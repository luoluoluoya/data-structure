* 借助数据结构来表示和组织的数字信息，可将所有数据视作一个整体统筹处理，进而提高信息访问的规范性及其处理的效率。例如，借助关键码直接查找和访问数据元素的形式，已为越来越多的数据结构所采用，这也成为现代数据结构的一个重要特征。
* 词典（dictionary）结构，即是其中最典型的例子。逻辑上的词典，是由一组数据构成的集合，其中各元素都是由关键码和数据项合成的词条（entry）。映射（map）结构与词典结构一样，也是词条的集合。二者的差别仅仅在于，映射要求不同词条的关键码互异，而词典则允许多个词条拥有相同的关键码。除了静态查找，映射和词典都支持动态更新，二者统称作**符号表（symbol table）**。实际上，“是否允许雷同关键码”应从语义层面，而非ADT接口的层面予以界定。
* 尽管此处词典和映射中的数据元素，仍表示和实现为词条形式，但这一做法并非必须。
* 符号表并不要求词条之间能够根据关键码比较大小。符号表查找对象亦不仅限于最大或最小的词条。在符号表的内部，甚至也不需要按照大小次序来组织数据项，即便各数据项之间的确定义有某种次序。
* 实际上，以散列表为代表的符号表结构，将转而依据数据项的数值，直接做逻辑查找和物理定位。也就是说，对于此类结构，在作为基本数据单位的词条内部，关键码（key）与数值（value）的地位等同，二者不必加以区分。此类结构所支持的这种新的数据访问方式，即所谓的循值访问（call-by-value）。相对于此前各种方式，这一方式更为自然，适用范围也更广泛。
* 既已抛开大小次序的概念，采用循值访问方式的计算过程，自然不再属于CBA式算法的范畴，此前关于CBA式算法下界的结论亦不再适用
* 当然，为支持循值访问的方式，在符号表的内部，仍然必须强制地在数据对象的数值与其物理地址之间建立某种关联。而所谓散列，正是在兼顾空间与时间效率的前提下，讨论和研究赖以设计并实现这种关联的一般性原则、技巧与方法

#### 词典ADT

* **操作接口**

  | 操 作 接 口 | 功 能 描 述 |
  | ----------- | ----------- |
  |             |             |
* 实际上，包括Snobol4、MUMPS、SETL、Rexx、Awk、Perl、Ruby、PHP、Java和Python等在内，许多编程语言都以各自不同形式，支持类似于以上词典或映射ADT接口功能的基本数据结构，有的甚至将它们作为基本的数据类型，统称作关联数组（associative array）。

* **接口定义**

  ```c++
  
  ```

* **实现方法**
  * 不难发现，基于此前介绍的任何一种平衡二叉搜索树，都可便捷地实现词典结构。比如，Java语言的java.util.TreeMap类即是基于红黑树实现的词典结构。然而这类实现方式都在不经意中假设“关键码可以比较大小”，故其所实现的并非严格意义上的词典结构。
  * 以下以跳转表和散列表为例介绍词典结构的两种实现方法。尽管它们都在底层引入了某种“序”，但这类“序”只是内部的一种约定；从外部接口来看，依然只有“相等”的概念。

##### 跳转表

* 前面所介绍的有序向量和有序列表，各有所长：前者便于静态查找，但动 态维护成本较高；后者便于增量式的动态维护，但只能支持顺序查找。为结合二者的优点，同时弥补其不足，第7章和第8章逐步引入了平衡二叉搜索树，其查找、插入和删除操作均可在 O(logn) 时间内完成。尽管如此，这些结构的相关算法往往较为复杂，代码实现和调试的难度较大，其正确性、鲁棒性和可维护性也很难保证。
* 设计并引入跳转表（skip list）结构的初衷，正是在于试图找到另外一种简便直观的方式，来完成这一任务。具体地，跳转表是一种高效的词典结构，它的定义与实现完全基于有序列表结构，其查询和维护操作在平均的意义下均仅需 O(logn) 时间。

* **跳转表结构接口**

  ```c++
  
  ```

* **总体逻辑结构**
  * ![image-20200512210257925](E:\Learn\repository\data-tructure\大话数据结构\images\image-20200512210257925.png)
  * 跳转表的宏观逻辑结构如图所示。其内部由沿横向分层、沿纵向相互耦合的多个列表{ S0, S1, S2, ..., Sh }组成，h称作跳转表的高度。
  * 每一水平列表称作一层（level），其中S0和Sh分别称作底层（bottom）和顶层（top）。与通常的列表一样，同层节点之间可定义前驱与后继关系。为便于查找，同层节点都按关键码排序。需再次强调的是，这里的次序只是内部的一种约定；对外部而言，各词条之间仍然只需支持判等操作即可。为简化算法实现，每层列表都设有头、尾哨兵节点。
  * 层次不同的节点可能沿纵向组成塔（tower），同一塔内的节点以高度为序也可定义前驱与后继关系。塔与词典中的词条一一对应。尽管塔内的节点相互重复，但正如随后将要看到的，这种重复不仅可以加速查找，而且只要策略得当，也不至造成空间的实质浪费。
  * 高层列表总是低层列表的子集，其中特别地，S0包含词典中的所有词条，而Sh除头、尾哨兵外不含任何实质的词条。不难看出，跳转表的层高h必然决定于最大的塔高。

###### 四联表

* 按上述约定，跳转表内各节点沿水平和垂直方向都可定义前驱和后继，支持这种联接方式的表称作四联表（quadlist）

* **四联表结构定义**

  ```c++
  
  ```
  * 此处定义的接口包括：定位首节点、末节点，在全表或某一区间查找具有特定关键码的节点，删除特定节点，以及插入特定节点。通过它们的相互组合，即可实现跳转表相应的接口功能。

* **四联表节点定义**

  ```c++
  
  ```
  * 为简化起见，这里并未做严格封装。对应于水平的前驱与后继，这里为每个节点设置了一对指针pred和succ；垂直方向的上邻和下邻则对应于above和below。主要的操作接口只有insertAsSuccAbove()，它负责创建新节点，并将其插入于当前节点之后、节点b之上。

* **初始化与构造**

  * 四联表的构造，实际上是通过调用如下init()函数完成的。

    ``` c++
    
    ```

* **查找**

  * 查找是跳转表至关重要和最实质的操作，词条的插入和删除等其它操作均以之为基础，其实现效率也将直接影响到跳转表结构的整体性能。

  * 实质的查找过程，只不过是从某层列表的首节点出发

    ```c++
    
    ```

* **空间复杂度**

  * **“生长概率逐层减半”条件**

    * 不难理解，其中各塔高度的随机分布规律（如最大值、平均值等），对跳转表的总体性能至关重要。反之，若不就此作出显式的限定，则跳转表的时间和空间效率都难以保证。比如，若将最大塔高（亦即跳转表的层高）记作h，则在极端情况下，每个词条所对应塔的高度均有可能接近甚至达到h。果真如此，在查找及更新过程中需要访问的节点数量将难以控制，时间效率注定会十分低下。同时，若词条总数为n，则在此类情况下，跳转表所需的存储空间量也将高达$\Omega(nh)$。
    * 然而幸运的是，若能采用简明而精妙的策略，控制跳转表的生长过程，则在时间和空间方面都可实现足够高的效率。就效果而言，此类控制策略必须满足所谓“生长概率逐层减半”条件：**对于任意$0\le k \lt h, S_k$中任一节点在$S_{k+1}$中依然出现的概率，始终为 1/2.**
    * 也就是说，S0中任一关键码依然在Sk中出现的概率，等于2^-k。这也可等效地理解和模拟为，在各塔自底而上逐层生长的过程中，通过投掷正反面等概率的理想硬币（fair coin），来决定是否继续增长一层.  亦即，对应于当前的词条，是否在上一层列表中再插入一个节点。

  * **节点总数的期望值**

    * 根据数学归纳法，“生长概率逐层减半”条件同时也意味着，列表S0中任一节点在列表Sk中依然出现的概率均为$1/2^k = 2^{-k}$。因此，第k层列表所含节点的期望数目为：$E(|S_k|) = n * 2^{-k}$, 亦即，各层列表的规模将随高度上升以50%的比率迅速缩小，故空间总体消耗量的期望值应为：
      $$
      E( \sum_k|S_k|) = \sum_kE(|S_k|) = n * (\sum_k2^{-k} ) < 2n = O(n)
      $$

* **时间复杂度**

 // -------------------

####  散列表

* 散列作为一种思想既朴素亦深刻，作为一种技术则虽古老却亦不失生命力，因而在数据结构及算法中占据独特而重要地位。此类方法以最基本的向量作为底层支撑结构，通过适当的散列函数在词条的关键码与向量单元的秩之间建立起映射关系。理论分析和实验统计均表明，只要散列表、散列函数以及冲突排解策略设计得当，散列技术可在期望的常数时间内实现词典的所有接口操作。也就是说，就平均时间复杂度的意义而言，可以使这些操作所需的运行时间与词典的规模基本无关。尤为重要的是，散列技术完全摒弃了“关键码有序”的先决条件，故就实现词典结构而言，散列所特有的通用性和灵活性是其它方式无法比拟的。

* **散列表**
  * 散列表（hashtable）是散列方法的底层基础，逻辑上由一系列可存放词条（或其引用）的单元组成，故这些单元也称作桶（bucket）或桶单元；与之对应地，各桶单元也应按其逻辑次序在物理上连续排列。因此，这种线性的底层结构用向量来实现再自然不过。为简化实现并进一步提高效率，往往直接使用数组，此时的散列表亦称作桶数组（bucket array）。若桶数组的容量为R，则其中合法秩的区间[0, R)也称作地址空间（address space）。 
* **散列函数**
  * 一组词条在散列表内部的具体分布，取决于所谓的散列（hashing）方案。
  * 事先在词条与桶地址之间约定的某种映射关系，可描述为从关键码空间到桶数组地址空间的函数：hash() : key  ->  hash(key)。这里的hash()称作散列函数（hash function）。反过来，hash(key)也称作key的散列地址（hashing address），亦即与关键码key相对应的桶在散列表中的秩。
* 每个桶恰好存放一个词条，既无空余亦无重复。这种在时间和空间性能方面均达到最优的散列，也称作完美散列（perfect hashing）。完美散列实际上并不常见。而在更多的应用环境中，为兼顾空间和时间效率，无论散列表或散列函数都需要经过更为精心的设计。
* 实际上，Bitmap结构也可理解为完美散列的一个实例。其中，为每个可能出现的非负整数，各分配了一个比特位，作为判定它是否属于当前集合的依据；散列函数也再简单不过， 各比特位在内部向量中的秩，就是其所对应整数的数值。
* **装填因子与空间利用率**
  * 尽管词典中实际需要保存的词条数N远远少于可能出现的词条数R，但R个词条中的任何一个都有可能出现在词典中。
  * 将散列表中非空桶的数目与桶单元总数的比值称作装填因子（load factor）。
* **散列函数**
  * 假定关键码均为 [0, R)范围内的整数。将词典中的词条数记作N，散列表长度记作M，于是通常有： R >> M > N，散列函数hash()的作用可理解为，将关键码空间[0, R)压缩为散列地址空间[0, M)
* **散列函数设计原则**
  * 确定性
    * 无论所含的数据项如何，词条E在散列表中的映射地址hash(E.key)必须完全取决于其关键码E.key。
  * 映射过程自身不能过于复杂，唯此方能保证散列地址的计算可快速完成，从而保证查询或修改操作整体的*O*(1)期望执行时间。
  * 所有关键码经映射后应尽量覆盖整个地址空间[0, M)，唯此方可充分利用有限的散列表空间。也就是说，函数hash()最好是满射。
  * 关键码映射到各桶的概率应尽量接近于1/M。(将关键码空间“均匀地”映射到散列地址空间，从而避免导致极端低效的情况)
* 总而言之，随机越强、规律性越弱的散列函数越好。当然，完全符合上述条件的散列函数并不存在，我们只能通过先验地消除可能导致关键码分布不均匀的因素，最大限度地模拟理想的随机函数，尽最大可能降低发生冲突的概率。
* **散列冲突（collision）**
  * 因定义域规模R远远大于取值域规模M，hash()不可能是单射。这就意味着，关键码不同的词条被映射到同一散列地址的情况难以彻底避免。
  * 若能在设计和选择散列函数阶段提前做些细致而充分的考量，便能尽可能地降低冲突发生的概率。
* **除余法（division method）**
  * 将散列表长度M取作为素数，并将关键码key映射至key关于M整除的余数：hash(key) = key mod M
  * 请注意，采用除余法时必须将M选作素数，否则关键码被映射至[0, M)范围内的均匀度将大幅降低，发生冲突的概率将随M所含素因子的增多而迅速加大。 
  * 在实际应用中，对同一词典内词条的访问往往具有某种周期性，若其周期与M具有公共的素因子，则冲突的概率将急剧攀升。
  * 一般地，散列表的长度M与词条关键码间隔T之间的最大公约数越大，发生冲突的可能性也将越大。因此，若M取素数，则简便对于严格或大致等间隔的关键码序列，也不致出现冲突激增的情况，同时提高空间效率。

* 词条集中到散列表内少数若干桶中（或附近）的现象，称作词条的聚集（clustering）。显然，好的散列函数应尽可能此类现象.

* **MAD法（multiply-add-divide method）**

  * 以素数为表长的除余法尽管可在一定程度上保证词条的均匀分布，但从关键码空间到散列地址空间映射的角度看，依然残留有某种连续性。比如，相邻关键码所对应的散列地址，总是彼此相邻；极小的关键码，通常都被集中映射到散列表的起始区段. 其中特别地，0值居然是一个“不动点”，其散列地址总是0，而与散列表长度无关。
  *  所谓的MAD法将关键码key映射为：(a * key + b ) mod M，其中M仍为素数，a > 0，b > 0，且a mod M != 0此类散列函数需依次执行乘法、加法和除法（模余）运算，故此得名。
  * 尽管运算量略有增加，但只要常数a和b选取得当，MAD法可以很好地克服除余法原有的连续性缺陷。
  * 实际上，此前所介绍的除余法，也可以看做是MAD法取a = 1和b = 0的特殊情况。从这一角度来看，导致除余法连续性缺陷的根源，也可理解为这两个常数未发挥实质的作用。

* **更多的散列函数**

  * 数字分析法（selecting digits）
  * 平方取中法（mid-square）
  * 折叠法（folding）
  * 位异或法（xor）
  * (伪)随机数法

* 越是随机、越是没有规律，就越是好的散列函数。按照这一标准，任何一个（伪）随机数发生器，本身即是一个好的散列函数。这一策略的原理也可理解为，将“设计好散列函数”的任务，转换为“设计好的（伪）随机数发生器”的任务。幸运的是，二者的优化目标几乎是一致的。需特别留意的是，由于不同计算环境所提供的（伪）随机数发生器不尽相同，故在将某一系统中生成的散列表移植到另一系统时，必须格外小心。

* **散列表**

* **Hashtable模板类**

  ```
  
  ```

* **散列表构造**

  ```c++
  
  ```

* 为了加速素数的选取，这里不妨事先计算出不超过1,048,576的所有素数，并存放于文件中备查。于是在创建散列表（或者重散列）时，对于在此范围内任意给定的长度下限c，都可迅速地从该查询表中找到不小于c的最小素数M作为散列表长度，并依此为新的散列表申请相应数量的空桶；同时创建一个同样长度的位图结构，作为懒惰删除标志表。

* **散列表析构**

  * 在销毁散列表之前，如代码9.16所示，需在逐一释放各桶中的词条（如果存在）之后，释放整个散列表ht[]以及对应的懒惰删除表。

  ```c++
  
  ```

* **冲突**
  * 散列表的基本构思，可以概括为：**开辟物理地址连续的桶数组ht[]，借助散列函数hash()，将词条关键码key映射为桶地址hash(key)，从而快速地确定待操作词条的物理位置。**
  * 然而遗憾的是，无论散列函数设计得如何巧妙，也不可能保证不同的关键码之间互不冲突。在实际应用中，不发生任何冲突的概率远远低于我们的想象。
* **多槽位（multiple slots）法**
  * ![image-20200512222555873](E:\Learn\repository\data-tructure\邓俊晖-数据结构\images\image-20200512222555873.png)
  * 最直截了当的一种对策是，将彼此冲突的每一组词条组织为一个小规模的子词典，分别存放于它们共同对应的桶单元中。比如一种简便的方法是，统一将各桶细分为更小的称作槽位（slot） 的若干单元，每一组槽位可组织为向量或列表。
  * 按照这一思路，针对关键码key的任一操作都将转化为对一组槽位的操作。比如put(key,value)操作，将首先通过hash(key)定位对应的桶单元，并在其内部的一组槽位中，进一步查找key。若失败，则创建新词条(key, value)，并将其插至该桶单元内的空闲槽位（如果的确还有的话）中。get(key)和remove(key)操作的过程，与此类似。
  * 多槽位法的缺陷，显而易见。首先由图9.10可见，绝大多数的槽位通常都处于空闲状态。准确地讲，若每个桶被细分为k个槽位，则当散列表总共存有N个词条时，装填因子p' = N/(kM) = p/k, 将降低至原先的1/k。
  * 其次，很难在事先确定槽位应细分到何种程度，方可保证在任何情况下都够用。比如在极端情况下，有可能所有（或接近所有）的词条都冲突于单个桶单元。此时，尽管几乎其余所有的桶都处于空闲状态，该桶却会因冲突过多而溢出
* **独立链（separate chaining）法**
  * ![image-20200512222804484](E:\Learn\repository\data-tructure\邓俊晖-数据结构\images\image-20200512222804484.png)
  * 冲突排解的另一策略与多槽位（multiple slots）法类似，也令相互冲突的每组词条构成小规模的子词典，只不过采用列表（而非向量）来实现各子词典。
  * 既然好的散列函数已能保证通常不致发生极端的冲突，故各子词典的规模往往都不是很大，大多数往往只含单个词条或者甚至是空的。
  * 相对于多槽位法，独立链法可更为灵活地动态调整各子词典的容量和规模，从而有效地降低空间消耗。但在查找过程中一旦发生冲突，则需要遍历整个列表，导致查找成本的增加。
* **公共溢出区法**
  * ![image](E:\Learn\repository\data-tructure\邓俊晖-数据结构\images\image-20200512223159401.png)
  * 公共溢出区（overflow area）法的思路如图9.12所示，在原散列表之外另设一个词典结构$D_{overflow}$，一旦在插入词条时发生冲突就将该词条转存至$D_{overflow}$中。就效果而言，$D_{overflow}$相当于一个存放冲突词条的公共缓冲池，该方法也因此得名。
  * 这一策略构思简单、易于实现，在冲突不甚频繁的场合不失为一种好的选择。同时，既然公共溢出区本身也是一个词典结构，不妨直接套用现有的任何一种实现方式因此就整体结构而言，此时的散列表也可理解为是一种递归形式的散列表
*  **闭散列策略**
  * 尽管就逻辑结构而言，独立链等策略便捷而紧凑，但绝非上策。比如，因需要引入次级关联结构，实现相关算法的代码自身的复杂程度和出错概率都将加大大增加。反过来，因不能保证物理上的关联性，对于稍大规模的词条集，查找过程中将需做更多的I/O操作。
  * 实际上，仅仅依靠基本的散列表结构，且就地排解冲突，反而是更好的选择。也就是说，若新词条与已有词条冲突，则只允许在散列表内部为其寻找另一空桶。如此，各桶并非注定只能存放特定的一组词条；从理论上讲，每个桶单元都有可能存放任一词条。因为散列地址空间对所有词条开放，故这一新的策略亦称作开放定址（open addressing）；同时，因可用的散列地址仅限于散列表所覆盖的范围之内，故亦称作闭散列（closed hashing）。相应地，此前的策略亦称作封闭定址（closed addressing）或开散列（open hashing）。
  * 当然，仅仅能够为冲突的词条选择一个可用空桶还不足够；更重要地，在后续的查找过程中应能正确地找到这个（些）词条。为此，须在事先约定好某种具体可行的查找方案。实际上，开放定址策略涵盖了一系列的冲突排解方法，包括线性试探法、平方试探法以及再散列法等。因不得使用附加空间，装填因子需要适当降低，通常都取 p <= 0.5。
*  **线性试探（linear probing）法** 
  * 开放定址策略最基本的一种形式是：在插入关键码key时，若发现桶单元ht[hash(key)]已被占用，则转而试探桶单元ht[hash(key) + 1]；若ht[hash(key) + 1]也被占用，则继续试探ht[hash(key) + 2]；...；如此不断，直到发现一个可用空桶。当然，为确保桶地址的合法，最后还需统一对M取模。因此准确地，第i次试探的桶单元应为：ht[ (hash(key) + i) mod M ]， i = 1, 2, 3, ...如此，被试探的桶单元在物理空间上依次连贯，其地址构成等差数列，该方法由此得名。
  * **查找链**
    * 采用开放地址策略时，散列表中每一组相互冲突的词条都将被视作一个有序序列，对其中任何一员的查找都需借助这一序列。对应的查找过程，可能终止于三种情况：
      * 在当前桶单元命中目标关键码，则成功返回；
      * 当前桶单元非空，但其中关键码与目标关键码不等，则须转入下一桶单元继续试探；
      * 当前桶单元为空，则查找以失败返回。
    * 相互冲突的关键码, 针对其中任一关键码的查找都将从ht[hash(key)]出发，试探各相邻的桶单元。与这组关键码对应的桶单元构成一个有序序列，对其中任一关键码的查找都将沿该序列顺序进行，故该序列亦称作查找链（probing chain）。
    * 可见，沿查找链试探的过程，与对应关键码此前的插入过程完全一致。因此对于长度为n的查找链，失败查找长度就是n + 1；在等概率假设下，平均成功查找长度为n/2。
    * 需强调的是，尽管相互冲突的关键码必属于同一查找链，但反过来，同一查找链中的关键码却未必相互冲突。究其原因在于，多组各自冲突的关键码所对应的查找链，有可能相互交织和重叠。此时，各组关键码的查找长度将会进一步增加。
  * **局部性**
    * 线性试探法中组成各查找链的词条，在物理上保持一定的连贯性，具有良好的数据局部性，故系统缓存的作用可以充分发挥，查找过程中几乎无需I/O操作。尽管闭散列策略同时也会在一定程度上增加冲突发生的可能，但只要散列表的规模不是很小，装填因子不是很大，则相对于I/O负担的降低而言，这些问题都将微不足道。也正因为此，相对于独立链等开散列策略，闭散列策略的实际应用更为广泛。
  * **懒惰删除**
    * 查找链中任何一环的缺失，都会导致后续词条因无法抵达而丢失，表现为有时无法找到实际已存在的词条。因此若采用开放定址策略，则在执行删除操作时，需同时做特别的调整。
    * 为保持查找链的完整，一种直观的构想是将后继词条悉数取出，然后再重新插入。很遗憾，如此将导致删除操作的复杂度增加，故并不现实。简明而有效的方法是，为每个桶另设一个标志位，指示该桶尽管目前为空，但此前确曾存放过词条。 
    * 具体地，为删除词条，只需将对应的桶ht[r]标志为lazilyRemoved(r)。如此，该桶虽不存放任何实质的词条，却依然是查找链上的一环。作此标记之后，对后继词条的查找仍可照常进行，而不致中断。这一方法既可保证查找链的完整，同时所需的时间成本也极其低廉，称作懒惰删除（lazy removal）法。
    * 请注意，设有懒惰删除标志位的桶，应与普通的空桶一样参与插入操作。需特别说明的是，此后不必清除该桶的懒惰删除标志, 尽管按照软件工程的规范，最好如此
    * 借助懒惰删除标志，的确可以避免查找链的断裂。当然，在此类查找中，也可将懒惰标志，等效地视作一个与任何关键码都不相等的特殊关键码
    * **两类查找**
      * 采用“懒惰删除”策略之后，get()、put()和remove()等操作中的查找算法，都需要做相应的调整。这里共分两种情况
      * 其一，在删除等操作之前对某一目标词条的查找。此时，对成功的判定条件基本不变，但对失败的判定条件需兼顾懒惰删除标志。在查找过程中，只有在当前桶单元为空，且不带懒惰删除标记时，方可报告“查找失败”；否则，无论该桶非空，或者带有懒惰删除标志，都将沿着查找链继续试探。
      * 其二，在插入等操作之前沿查找链寻找空桶。此时对称地，无论当前桶为空，还是带有懒惰删除标记，均可报告“查找成功”；否则，都将沿查找链继续试探。(请注意，这 里共有两种试探终止的可能：在一个非空的桶内找到目标关键码（成功），或者遇到一个不带懒惰删除标记的空桶（失败）。否则，无论是当前桶中词条的关键码与目标关键码不等，还是当前桶为空但带有懒惰删除标记，都意味着有必要沿着查找链前进一步继续查找。)
* **装填因子**
  * 对散列表性能及效率的影响而言，装填因子p = N / M是最为重要的一个因素。随着p的上升，词条在散列表中聚集的程度亦将迅速加剧。
  * 实际上，理论分析和实验统计均一致表明，只要能将装填因子控制在适当范围以内，闭散列策略的平均效率，通常都可保持在较为理想的水平。比如，一般的建议是保持p < 0.5。这一原则也适用于其它的定址策略，比如对独立链法而言，建议的装填因子上限为0.9。当前主流的编程语言大多提供了散列表接口，其内部装填因子的阈值亦多采用与此接近的阈值。
  * **重散列（rehashing）**
    * 其实，将装填因子控制在一定范围以内的方法并不复杂，重散列即是常用的一种方法。
    * 重散列算法：装填因子过大时，采取逐一取出再插入的朴素策略，对桶数组扩容。可见，重散列的效果，只不过是将原词条集，整体“搬迁”至容量至少加倍的新散列表中。与可扩充向量同理，这一策略也可使重散列所耗费的时间，在分摊至各次操作后可以忽略不计。
* **更多闭散列策略**
  * **聚集现象**
    * 线性试探法虽然简明紧凑，但各查找链均由物理地址连续的桶单元组成，因而会加剧关键码的聚集趋势。
  * **平方试探（quadratic probing）法**
    * 采用MAD法，可在一定程度上缓解上述聚集现象。而平方试探法，则是更为有效的一种方法。具体地，在试探过程中若连续发生冲突，则按如下规则确定第j次试探的桶地址：(hash(key) + j2 ) mod M, j = 0, 1, 2, ... 各次试探的位置到起始位置的距离，以平方速率增长，该方法因此得名。
    * 

