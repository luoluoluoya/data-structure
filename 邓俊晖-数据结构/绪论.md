#### 计算机与算法
* 计算机是人类从事计算的工具，是抽象计算模型的具体物化。基于图灵模型的现代计算机，既是人类现代文明的标志与基础，更是人脑思维的拓展与延伸。
* 尽管计算机的性能日益提高，但这种能力在解决实际应用问题时能否真正得以发挥，决定性的关键因素仍在于人类自身。
* 通过深入思考与分析获得对问题本质的透彻理解，按照长期积淀而成的框架与模式设计出合乎问题内在规律的算法，选用、改进或定制足以支撑算法高效实现的数据结构，并在真实的应用环境中充分测试、调校和改进，构成了应用计算机高效求解实际问题的典型流程与不二法门。
* 1946年问世的ENIAC开启了现代电子数字计算机的时代，计算机科学（computer science）也在随后应运而生。**计算机科学的核心在于研究计算方法与过程的规律，而不仅仅是作为计算工具的计算机本身**，因此E. Dijkstra及其追随者更倾向于将这门科学称作计算科学（computing science）。
* 人类使用不同工具从事计算的历史可以追溯到更为久远的时代，计算以及计算工具始终与我们如影相随地穿越漫长的时光岁月，不断推动人类及人类社会的进化发展。从最初颜色各异的贝壳、长短不一的刻痕、周载轮回的日影、粗细有别的绳结，以至后来的直尺、圆规和算盘，都曾经甚至依然是人类有力的计算工具。
  * 用于支持和实现计算过程的物理机制，亦即广义的计算机。
    * 古埃及人的绳索
    * 欧几里得的尺规

##### 起泡排序

* D. Knuth曾指出，四分之一以上的CPU时间都用于执行同一类型的计算：按照某种约定的次序，将给定的一组元素顺序排列，比如将n个整数按通常的大小次序排成一个非降序列。这类操作统称排序（sorting）。

* 就广义而言，我们今天借助计算机所完成的计算任务中，有更高的比例都可归入此类。例如，从浩如烟海的万维网中找出与特定关键词最相关的前100个页面，就是此类计算的一种典型形式。排序问题在算法设计与分析中扮演着重要的角色，以下不妨首先就此做一讨论。为简化起见，这里暂且只讨论对整数的排序。

* **局部有序与整体有序**

  * 在由一组整数组成的序列A[0, n - 1]中，满足 A[i - 1]  <= A[i] 的相邻元素称作顺序的；否则是逆序的。不难看出，有序序列中每一对相邻元素都是顺序的，亦即,对任意1 <= i < n都有A[i - 1] <= A[i]；反之，所有相邻元素均顺序的序列，也必然整体有序。

* **扫描交换**

  * 由有序序列的上述特征，我们可以通过**不断改善局部的有序性实现整体的有序**：从前向后依次检查每一对相邻元素，一旦发现逆序即交换二者的位置。对于长度为n的序列，共需做n - 1次比较和不超过n - 1次交换，这一过程称作一趟扫描交换。

* **起泡排序**

  * 经过一趟扫描，序列未必达到整体有序。果真如此，则可对该序列再做一趟扫描交换，直到在序列中不再含有任何逆序的相邻元素。多数的这类交换操作，都会使得越小（大）的元素朝上（下）方移动（，直至它们抵达各自应处的位置。
  * 排序过程中，所有元素朝各自最终位置亦步亦趋的移动过程，犹如气泡在水中的上下沉浮，起泡排序（bubblesort）算法也因此得名。

* **整数数组癿起泡排序算法实现**

  ```c
  void swap(int *a, int *b)
  {
      int tmp = *a;
      *a = *b;
      *b = tmp;
  }
  
  void bubblesort1A(int * arr, int num)
  {
      unsigned short sorted = 0;  //整体排序标志，首先假定尚未排序
      while (!sorted) { //在尚未确讣已全尿排序乀前，逐趟迕行扫描交换
          sorted = 1; //假定已经排序
          for (int i = 1; i < num; ++i) {  //自左向右逐对检查弼前范围A[0, n)内癿各相邻元素
              if (*(arr+i-1) > *(arr+i)) {  //一旦A[i - 1]不A[i]逆序，则交换
                  sorted = 0;   //因整体排序丌能保证，需要清除排序标志
                  swap(arr+i-1, arr+i); 
              }
          }
          num--;
      }
  }
  ```

* **算法**

* 究竟什么是算法呢？

  * 所谓算法，是指基于特定的计算模型，旨在解决某一信息处理问题而设计的一个指令序列。
    * 比如，针对“过直线上一点作垂直线”这一问题，基于由绳索和奴隶构成的计算模型，由古埃及人设计的古埃及人的绳索算法；
    * 针对“三等分线段”这一问题，基于由直尺和圆规构成的计算模型，由欧几里得设计的欧几里得的尺规算法；
    * 针对“将若干元素按大小排序”这一问题，基于图灵机模型而设计的bubblesort1A()算法，等等。

* 算法还应必须具备要素

  * 输入与输出

    * 待计算问题的任一实例，都需要以某种方式交给对应的算法，对所求解问题特定实例的这种描述统称为输入（input）
    * 经计算和处理之后得到的信息，即针对输入问题实例的答案，称作输出（output）
    * 在物理上，输出有可能存放于单独的存储空间中，也可能直接存放于原输入所占的存储空间中

  * 基本操作、确定性与可行性

    * 所谓确定性和可行性是指，算法应可描述为由若干语义明确的基本操作（基本操作的适当组合）组成的指令序列，且每一基本操作在对应的计算模型中均可兑现

    * 从现代程序设计语言的角度，可以更加便捷而准确地理解算法的确定性与可行性。具体地，一个算法满足确定性与可行性，当且仅当它可以通过程序设计语言精确地描述，比如，起泡排序算法可以具体地描述和实现为代码中的函数bubblesort1A()，其中“读取某一元素的内容”、“修改某一元素的容”、“比较两个元素的大小”、“逻辑表达式求值”以及“根据逻辑判断确定分支转向”等等，都属于现代电子计算机所支持的基本操作。

  * 有穷性与正确性

    * 不难理解，任意算法都应在执行有限次基本操作之后终止并给出输出，此即所谓算法的有穷性（finiteness）。
    * 算法不仅应该迟早会终止，而且所给的输出还应该能够符合由问题本身在事先确定的条件，此即所谓算法的正确性（correctness）。
    * 证明算法有穷性和正确性的一个重要技巧，就是从适当的角度审视整个计算过程，并找出其所具有的某种不变性和单调性。
      * 单调性通常是指，问题的有效规模会随着算法的推进不断递减。
      * 不变性则不仅应在算法初始状态下自然满足，而且应与最终的正确性相呼应。当问题的有效规模缩减到0时，不变性应随即等价于正确性。

  * 退化与鲁棒性

    * 同一问题往往不限于一种算法，而同一算法也常常会有多种实现方式，因此除了以上必须具备的基本属性，在应用环境中还需从实用的角度对不同算法及其不同版本做更为细致考量和取舍。这些细致的要求尽管应纳入软件工程的范畴，但也不失为成熟算法的重要标志。
      * 比如其中之一就是，除一般性情况外，实用的算法还应能够处理各种极端的输入实例。仍以排序问题为例，极端情况下待排序序列的长度可能不是正数（参数n = 0甚至n < 0），或者反过来长度达到或者超过系统支持的最大值（n = INT_MAX），或者arr[]中的元素不见得互异甚至全体相等，以上种种都属于所谓的退化（degeneracy）情况。算法所谓的鲁棒性（robustness），就是要求能够尽可能充分地应对此类情况。

  * 重用性

    * 从实用角度评判不同算法及其不同实现方式时，可采用的另一标准是：算法的总体框架能否便捷地推广至其它场合。
      * 以起泡排序为例。实际上，起泡算法的正确性与所处理序列中元素的类型关系不大，无论是对于float、char或其它类型，只要元素之间可以比较大小，算法的整体框架就依然可以沿用。算法模式可推广并适用于不同类型基本元素的这种特性，即是重用性的一种典型形式。很遗憾，代码所实现的bubblesort1A()算法尚不满足这一要求；

* **起泡排序分析**

  * 在起泡交换的过程中，尽管多数时候元素会朝着各自的最终位置不断靠近，但有的时候某些元素也的确会暂时朝着远离自己应处位置的方向移动
  * 每经过一趟扫描交换，尽管并不能保证序列立即达到整体有序，但从“待求解问题的规模”这一角度来看，整体的有序性必然有所改善。以全局最大的元素为例，在第一趟扫描交换的过程中，一旦触及该元素，它必将与后续的所有元素依 次交换。经过第一趟扫描之后，该最大元素必然就位；而且在此后的各趟扫描交换中，该元素将绝不会参与任何交换。这就意味着，经过一趟扫描交换之后，我们只需 要关注前面更小的那n - 1个元素。实际上，这一结论对后续的各趟扫描交换也都成立。 于是，起泡排序算法的不变性和单调性可分别概括为：经过k趟扫描交换之后，最大的前 k个元素必然就位；经过 k 趟扫描交换之后，待求解问题的有效规模将缩减至 n - k。
  * 反观如bubblesort1A()算法代码所示的，外层while循环会不断缩减待排序序列的有效长度n。现在我们已经可以理解，该算法之所以能够如此处理，正是基于以上不变性和单调性。特别地，初始状态下 k = 0，这两条性质都自然满足。另一方面，由以上单调性可知，无论如何，至多经n - 1趟扫描交换后，问题的有效规模必将缩减至1。此时，仅含单个元素的序列，有序性不言而喻；而由该算法的不变性，其余 n - 1 个元素在此前的 n - 1 步迭代中业已相继就位。因此，算法不仅必然终止，而且输出序列必然整体有序，其有穷性与正确性由此得证。

* **算法效率**
  * **可计算性**
    * 学习程序设计语言的目的，在于学会如何编写合法（即合乎特定程序语言的语法）的程序，从而保证编写的程序或者能够经过编译和链接生成执行代码，或者能够由解释器解释执行。然而从通过计算有效解决实际问题的角度来看，这只是第一个层次，仅仅做到语法正确还远远不够。很遗憾，算法所应具备的更多基本性质，合法的程序并非总是自然具备。
    * 以前面提到的有穷性为例，完全合乎语法的程序却往往未必能够满足。相信每一位编写过程序的读者都有过这样的体验：很多合法的程序可以顺利编译链接，但在实际运行的过程中却因无穷循环或递归溢出导致异常。更糟糕的是，就大量的应用问题而言，根本就不可能设计出必然终止的算法。从这个意义讲，它们都属于不可解的问题。
  * **难解性**
    * 实际上我们不仅需要确定，算法对任何输入都能够在有穷次操作之后终止，而且更加关注该过程所需的时间。很遗憾，很多算法即便满足有穷性，但在终止之前所花费的时间成本却太高。
  * **计算效率**
    * 更多地关注于非“不可解和难解”的一般性问题，并讨论如何高效率地解决这一层面的计算问题。为此，首先需要确立一种尺度，用以从时间和空间等方面度量算法的计算成本，进而依此尺度对不同算法进行比较和评判。当然，更重要的是研究和归纳算法设计与实现过程中的一般性规律与技巧，以编写出效率更高、能够处理更大规模数据的程序。
  * **数据结构**
    * 无论是算法的初始输入、中间结果还是最终输出，在计算机中都可以数据的形式表示。对于数据的存储、组织、转移及变换等操作，不同计算模型和平台环境所支持的具体形式不尽相同，其执行效率将直接影响和决定算法的整体效率。数据结构这一学科正是以“数据”这一信息的表现形式为研究对象，旨在建立支持高效算法的数据信息处理策略、技巧与方法。要做到根据实际应用需求自如地设计、实现和选用适当的数据结构，必须首先对算法设计的技巧以及相应数据结构的特性了然于心。

##### 复杂度度量

###### 时间复杂度

* 如何度量一个算法所需的计算时间呢?

  * 上述问题并不容易直接回答，原因在于，运行时间是由多种因素综合作用而决定的。首先，即使是同一算法，对于不同的输入所需的运行时间并不相同。
    * 排序问题为例，输入序列的规模、其中各元素的数值以及次序均不确定，这些因素都将影响到排序算法最终的运行时间。
  * 为针对运行时间建立起一种可行、可信的评估标准，我们不得不首先考虑其中**最为关键的因素**。其中，问题实例的规模往往是决定计算成本的主要因素。一般地，问题规模越接近，相应的计算成本也越接近；而随着问题规模的扩大，计算成本通常也呈上升趋势。

* 随着输入规模的扩大，算法的执行时间将如何增长？

  * 根据规模并不能唯一确定具体的输入，规模相同的输入通常都有多个，而算法对其进行处理所需时间也不尽相同。
    * 以排序问题为例，由n个元素组成的输入序列有n!种，有时所有元素都需交换，有时却无需任何交换
  * 执行时间的这一变化趋势可表示为输入规模的一个函数，称作该算法的时间复杂度（time complexity）。具体地，**特定算法处理规模为 n 的问题中选择执行时间最长者作为T(n)**，并以T(n)度量该算法的时间复杂度

* 至此，对于同一问题的两个算法A和B，通过比较其时间复杂度TA(n)和TB(n)，即可评价二者对于同一输入规模n的计算效率高低。然而，藉此还不足以就其性能优劣做出总体性的评判，

  * 对于某些问题，一些算法更适用于小规模输入，而另一些则相反

* 渐进分析（asymptotic analysis）

  * 在评价算法运行效率时，我们往往可以忽略其处理小规模问题时的能力差异，转而关注其在处理更大规模问题时的表现。其中的原因不难理解，小规模问题所需的处理时间本来就相对更少，故此时不同算法的实际效率差异并不明显；而在处理更大规模的问题时，效率的些许差异都将对实际执行效果产生巨大的影响。这种**着眼长远、更为注重时间复杂度的总体变化趋势和增长速度的策略与方法**，即所谓的渐进分析（asymptotic analysis）

* **大O记号**

  * 若存在正的常数c和函数f(n)，使得对任何 n >> 2都有 T(n)  <=  c∙f(n). 则可认为在n足够大之后，f(n)给出了T(n)增长速度的一个渐进上界。此时，记之为：T(n) = *O*(f(n));
    * 对于任一常数 c > 0，有O(f(n)) = O(c∙f(n))
      * 在大*O*记号的意义下，函数各项正的常系数可以忽略并等同于1
    * 对于任意常数a > b > 0，有O(n^a + n^b) = O(n^a)
      * 多项式中的低次项均可忽略，只需保留最高次项

* **环境差异**

  * 在实际环境中直接测得的执行时间T(n)，虽不失为衡量算法性能的一种指标，但作为评判不同算法性能优劣的标准，其可信度值得推敲。事实上，即便是同一算法、同一输入，在不同的*硬件平台*上、不同的*操作系统*中甚至*不同的时间*，所需要的计算时间都不尽相同。因此，有必要按照超脱于具体硬件平台和软件环境的某一客观标准，来度量算法的时间复杂度，并进而评价不同算法的效率差异。

* **基本操作**

  * **将时间复杂度理解为算法中各条指令的执行时间之和**
  * 在图灵机（Turing Machine, TM）和随机存储机（Random Access Machine, RAM）等计算模型中，**指令语句均可分解为若干次基本操作**，比如算术运算、比较、分支、子程序调用与返回等；而在大多数实际的计算环境中，每一次这类基本操作都可在常数时间内完成
  * 不妨**将 T(n) 定义为算法所执行基本操作的总次数**。也就是说，T(n) 决定于组成算法的所有语句各自的执行次数，以及其中所含基本操作的数目
  * 起泡排序基本操作分析
    * bubblesort1A()算法由内、外两层循环组成。内循环从前向后，依次比较各对相邻元素，如有必要则将其交换。故在每一轮内循环中，需要扫描和比较n - 1对元素，至多需要交换n - 1对元素。元素的比较和交换，都属于基本操作，故每一轮内循环至多需要执行2(n - 1)次基本操作。另外，外循环至多执行n - 1轮。因此，总共需要执行的基本操作不会超过2(n - 1)^2次。若以此来度量该算法的时间复杂度，则有T(n) = *O*(2(n-1)^2)根据大*O*记号的性质，可进一步简化和整理为：T(n) = *O*(2n^2 - 4n + 2) = *O*(2n^2) = *O*(n^2) 

* **最坏、最好与平均情况**

  * 以大*O*记号形式表示的时间复杂度，实质上是对算法执行时间的一种保守估计. 对于规模为n的任意输入，算法的运行时间都不会超过*O*(f(n))
    * 起泡排序算法复杂度$T(n) = O(n^2)$意味着，该算法处理任何序列所需的时间绝不会超过$O(n^2)$
  * 需强调的是，这种保守估计并不排斥更好情况甚至最好情况（best case）的存在和出现
    * 比如，对于某些输入序列，起泡排序算法的内循环的执行轮数可能少于n-1，甚至只需执行一轮
  * 当然，有时也需要考查所谓的平均情况（average case），也就是按照某种约定的概率分布，将规模为n的所有输入对应的计算时间加权平均。
  * 比较而言，“最坏情况复杂度”是人们最为关注且使用最多的，在一些特殊的场合甚至成为唯一的指标。比如控制核电站运转、管理神经外科手术室现场的系统而言，从最好或平均角度评判算法的响应速度都不具有任何意义，在最坏情况下的响应速度才是唯一的指标。

* **大$\Omega$记号**

  * 为了**对算法的复杂度最好情况做出估计**，需要借助另一个记号。如果存在正的常数 c 和函数 g(n)，使得对于任何 n >> 2都有 T(n)  >= c∙g(n)。 就可以认为，在n足够大之后，g(n)给出了T(n)的一个渐进下界。此时，我们记之为：$T(n) = \Omega(g(n))$. 这里的$\Omega$称作“大$\Omega$记号”（big-omega notation）。与大*O*记号恰好相反，**大$\Omega$记号是对算法执行效率的乐观估计**. 对于规模为n的任意输入，算法的运行时间都不低于$\Omega$(g(n))。
    * 即便在最好情况下，起泡排序也至少需要T(n) = $\Omega$(n)的计算时间

* **大$\Theta$记号**

  * 借助大*O*记号、大 $\Omega$ 记号，可以对算法的时间复杂度作出定量的界定，亦即，从渐进的趋势看，T(n)介于$\Omega$(g(n))与*O*(f(n))之间。

  * 若恰巧出现g(n) = f(n)的情况，则可以使用另一记号来表示。如果存在正的常数 c1 < c2 和函数 h(n)，使得对于任何 n >> 2都有 c1∙h(n)  <= T(n) <=  c2∙h(n). 就可以认为在n足够大之后，h(n)给出了T(n)的一个确界。此时，我们记之为： $T(n) = \Theta (h(n))$这里的$\Theta$称作“大$\Theta$记号”（big-theta notation），它是**对算法复杂度的准确估计**. 对于规模为n的任何输入，算法的运行时间T(n)都与$\Theta$(h(n))同阶。

    

  ![image-20200502083107349](C:\Users\47302\AppData\Roaming\Typora\typora-user-images\image-20200502083107349.png)



###### 空间复杂度

* 除了执行时间的长短，**算法所需存储空间的多少**也是衡量其性能的一个重要方面，此即所谓的空间复杂度（space complexity）。
* 需要注意的是，为了更为客观地评价算法性能的优劣，除非特别申明，**空间复杂度通常并不计入原始输入本身所占用的空间**。 对于同一问题，这一指标对任何算法都是相同的。反之，其它（如转储、中转、索引、映射、缓冲等）各个方面所消耗的空间，则都应计入。
* 另外，很多时候我们都是更多地甚至仅仅关注于算法的时间复杂度，而不必对空间复杂度做专门的考查。这种简便评测方式的依据，来自于以下事实：就渐进复杂度的意义而言，在任一算法的任何一次运行过程中所消耗的存储空间，都不会多于其间所执行基本操作的累计次数。
* 实际上根据定义，**每次基本操作所涉及的存储空间，都不会超过常数规模**；纵然每次基本操作所占用或访问的存储空间都是新开辟的，整个算法所需的空间总量，也不过与基本操作的次数同阶。从这个意义上说，**时间复杂度本身就是空间复杂度的一个天然的上界**
* 当然，对空间复杂度的分析也有其自身的意义，尤其在对空间效率非常在乎的应用场合中，或当问题的输入规模极为庞大时，由时间复杂度所确立的平凡上界已经难以令人满意。这类情况下，人们将更为精细地考查不同算法的空间效率，并尽力在此方面不断优化。

#####  复杂度分析

* 在明确了算法复杂度的度量标准之后，如何分析具体算法的复杂度呢？所引入的三种记号中，大*O*记号是最基本的，也是最常用到的。从渐进分析的角度，大*O*记号将各算法的复杂度由低到高划分为若干层次级别。

* **常数O(1)**

  * 运行时间可表示和度量为T(n) = *O*(1)的这一类算法，统称作“常数时间复杂度算法” （constant-time algorithm）。此类算法已是最为理想的，因为不可能奢望“不劳而获”。
  * 一般地，**仅含一次或常数次基本操作的算法**均属此类。*此类算法通常不含循环、分支、子程序调用等*，但也不能仅凭语法结构的表面形式一概而论
  * 除了输入数组等参数之外，该算法仅需常数规模的辅助空间。此类仅需*O*(1)辅助空间的算法，亦称作**就地算法**（in-place algorithm）。

* **对数O(logn)**

  * 由大*O*记号定义，在用函数$log_rn$界定渐进复杂度时，常底数 r 的具体取值无所谓，故通常不予专门标出而笼统地记作$logn$。比如，尽管此处底数为常数2，却可直接记作$O（logn）$。此类算法称作具有“对数时间复杂度”（logarithmic-time algorithm）。

  * 示例程序

    ```
     //统计整数二迕刢展开中数位1癿总数：O(logn)
    int countOnes(unsigned int n)
    {
        int ones = 0;
        while (0 < n) {
            ones += (n&1);
            n >>= 1;
        }
        return ones;
    }
    ```

* **对数多项式复杂度**

  * 更一般地，凡运行时间可以表示和度量为$T(n) = O(log^c n)$形式的这一类算法（其中常数c > 0），均统称作“对数多项式时间复杂度的算法”（polylogarithmic-time algorithm）。
    *  *O*(logn)即 c = 1的特例。
  * 此类算法的效率虽不如常数复杂度算法理想，但从多项式的角度看仍能无限接近于后者，故也是极为高效的一类算法。

* **线性O(n)**

  * 凡运行时间可以表示和度量为T(n) = *O*(n)形式的这一类算法，均统称作“线性时间复杂度算法”（linear-time algorithm）。也就是说，**对于输入的每一单元，此类算法平均消耗常数时间**。**就大多数问题而言，在对输入的每一单元均至少访问一次之前，不可能得出解答**。以数组求和为例，在尚未得知每一元素的具体数值之前，绝不可能确定其总和。故就此意义而言，此类算法的效率亦足以令人满意。

  * 示例程序

    ```
     //数组求和算法（迭代版）
    int sumI ( int A[], int n ) {
        int sum = 0; //刜始化累计器，O(1)
        for ( int i = 0; i < n; i++ ) //对全部共O(n)个元素，逐一
        	sum += A[i]; //累计，O(1)
        return sum; //迒回累计值，O(1)
    } 
    //O(1) + O(n)*O(1) + O(1) = O(n+2) = O(n)
    ```

* **多项式O(polynomial(n))**
  * 若运行时间可以表示和度量为T(n) = *O*(f(n))的形式，而且f(x)为多项式，则对应的算法称作“多项式时间复杂度算法”（polynomial-time algorithm）。
    * 线性时间复杂度算法，也属于多项式时间复杂度算法的特例，其中线性多项式 f(n) = n 的次数为1
  * 在算法复杂度理论中，多项式时间复杂度被视作一个具有特殊意义的复杂度级别。多项式级的运行时间成本，在实际应用中一般被认为是可接受的或可忍受的。某问题若存在一个复杂度在此范围以内的算法，则称该问题是**可有效求解的或易解的**（tractable）。
  * 请注意，这里仅要求多项式的次数为一个正的常数，而并未对其最大取值范围设置任何具体上限，故实际上该复杂度级别涵盖了很大的一类算法。比如，从理论上讲，复杂度分别为*O*(n^2) 和*O*(n^2012)算法都同属此类，尽管二者实际的计算效率有天壤之别。之所以如此，是因为相对于以下的指数级复杂度，二者之间不超过多项式规模的差异只是小巫见大巫。

* **指数O(2^n)**

  * 凡运行时间可以表示和度量为T(n) = *O*(an)形式的算法（a > 1），均属于“指数时间复杂度算法”（exponential-time algorithm）。 

    

* **从多项式到指数**

  * 从常数、对数、线性、平方到多项式时间复杂度，算法效率的差异还在可接受的范围。然而，在多项式与指数时间复杂度之间，却有着一道巨大的鸿沟。当问题规模较大后，指数复杂度算法的实际效率将急剧下降，计算时间之长很快就会达到令人难以忍受的地步。因此通常认为，指数复杂度算法无法真正应用于实际问题中，它们不是有效算法，甚至不能称作算法。相应地，不存在多项式复杂度算法的问题，也称作**难解的（intractable）问题**。
  * 需注意的是，在问题规模不大时，指数复杂度反而可能在较长一段区间内均低于多项式复杂度；但前者迟早必然超越后者，且随着n的进一步增大，二者的差距无法保持在多项式倍的范围。因此，从渐进复杂度的角度看，多项式与指数是无法等量齐观的两个截然不同的量级。
  * 实际上很遗憾，绝大多数计算问题并不存在多项式时间的算法，也就是说，试图求解此类问题的任一算法，都至少需要运行指数量级的时间。特别地，很多问题甚至需要无穷的时间，由于有穷性不能满足或者尚未得到证明也可以说不存在解决这些问题的算法。

* 典型的复杂度层次包括$O(1)、O(log^*n)、O(log{logn})、O(logn)、O(\sqrt n)、O(n)、O(nlog^*n)、O(nlog{logn})、O(nlog{n})、O(n^3)、O(n^c)、O(2^n)$等

* **输入规模**

  * 对算法复杂度的界定，都是相对于问题的输入规模而言的。然而，不同的人在不同场合下关于“输入规模”的理解、定义和度量可能不尽相同，因此也可能导致复杂度分析的结论有所差异
  * 严格地说，所谓待计算问题的输入规模，应严格定义为“**用以描述输入所需的空间规模**”。

##### 递归

* **分支转向是算法的灵魂；函数和过程及其之间的相互调用，是在经过抽象和封装之后，实现分支转向的一种重要机制；**而递归则是函数和过程调用的一种特殊形式，即允许函数和过程进行自我调用。因其高度的抽象性和简洁性，递归已成为多数高级程序语言普遍支持的一项重要特性。

  * 比如在C++语言中，递归调用（recursive call）就是某一方法调用自身。这种自我调用通常是*直接的*，即在函数体中包含一条或多条调用自身的语句。*递归也可能以间接的形式出现*，即某个方法首先调用其它方法，再辗转通过其它方法的相互调用，最终调用起始的方法自身。

* 递归的价值在于，许多应用问题都可简洁而准确地描述为递归形式。

  * 操作系统为例，多数文件系统的目录结构都是递归定义的。

* **递归也是一种基本而典型的算法设计模式**。这一模式可以对实际问题中反复出现的结构和形式做高度概括，并从本质层面加以描述与刻画，进而导出高效的算法。从程序结构的角度看，**递归模式能够统筹纷繁多变的具体情况，避免复杂的分支以及嵌套的循环**，从而更为简明地描述和实现算法，减少代码量，提高算法的可读性，保证算法的整体效率。

  * 线性递归、二分递归和多分支递归等

* 保证递归算法有穷性

  * 首先判断并处理**平凡情况**，以免因无限递归而导致系统溢出。这类平凡情况统称“**递归基**”（base case of recursion）。平凡情况可能有多种，但至少要有一种，且迟早必然会出现。

* **线性递归**

  * 算法可能朝着更深一层进行自我调用，且**每一递归实例对自身的调用至多一次。于是，每一层次上至多只有一个实例，且它们构成一个线性的次序关系**。此类递归模式因而称作“线性递归”（linear recursion），它也是递归的最基本形式。
  * 这种形式中，应用问题总可分解为两个独立的子问题：
    * **其一对应于单独的某个元素，故可直接求解**；
    * **另一个对应于剩余部分，且其结构与原问题相同**。另外，子问题的解经简单的合并（比如整数相加）之后，即可得到原问题的解。
  * **减而治之**
    * 线性递归的模式，往往对应于所谓减而治之（decrease-and-conquer）的算法策略：**递归每深入一层，待求解问题的规模都缩减一个常数，直至最终蜕化为平凡的小（简单）问题。按照减而治之策略，此处随着递归的深入，调用参数将单调地线性递减**。因此无论最初输入的n有多大，递归调用的总次数都是有限的，故算法的执行迟早会终止，即满足有穷性。当抵达递归基时，算法将执行非递归的计算.

* **二分递归**

  * 面对输入规模庞大的应用问题，往往头绪纷杂而无从下手。解决此类问题的有效方法之一，就是**将其分解为若干规模更小的子问题，再通过递归机制分别求解。这种分解持续进行，直到子问题规模缩减至平凡情况。这也就是所谓的分而治之（divide-and-conquer）策略**。

  * 与减而治之策略一样，这里也**要求对原问题重新表述，以保证子问题与原问题在接口形式上的一致。**既然每一递归实例都可能做多次递归，故称作“**多路递归**”（multi-way recursion）。通常都是将原问题一分为二，故称作“二分递归”（binary recursion）。需强调的是，**无论是分解为两个还是更大常数个子问题，对算法总体的渐进复杂度并无实质影响。**

  * 二分递归实现数组求和

    ```c
    int sum(int *arr, int start, int end)
    {
        if (start == end) {
            return *(arr+start);
        }
        int mid = (start + end) >> 1;
        return sum(arr, start, mid) + sum(arr, mid + 1, end);
    }
    ```

    ![image-20200502102727494](C:\Users\47302\AppData\Roaming\Typora\typora-user-images\image-20200502102727494.png)

  * 针对n = 8的情况给出了sum(A, 0, 7)执行过程的递归跟踪。其中各方框都标注有对应的lo和hi值，即子数组区间的起、止单元。可见，按照调用的关系及次序，该方法的所有实例构成一个层次结构。沿着这个层次结构每下降一层，每个递归实例sum(lo, hi)都分裂为一对更小的实例sum(lo, mi), sum(mi + 1, hi)。准确地说，每经过一次递归调用，子问题对应的数组区间长度hi - lo + 1都将减半。

  * 算法启动后经连续$m = log_2n$次递归调用，数组区间的长度从最初的n首次缩减至1，并到达第一个递归基。实际上，刚到达任一递归基时，已执行的递归调用总是比递归返回多 $m = log_2n$次。更一般地，到达区间长度为2^k的任一递归实例之前，已执行的递归调用总是比递归返回多 m-k 次。因此，递归深度（即任一时刻的活跃递归实例的总数）不会超过m + 1。鉴于每个递归实例仅需常数空间，故除数组本身所占的空间，该算法只需要$O(m + 1) = O(logn)$的附加空间。我们还记得，线性递归版sum()算法共需*O*(n)的附加空间，就这一点而言，新的二分递归版sum()算法有很大改进。

  * 与线性递归版sum()算法一样，此处每一递归实例中的非递归计算都只需要常数时间。递归实例共计 2n - 1个，故新算法的运行时间为*O*(2n - 1) = *O*(n)，与线性递归版相同。

  * 此处每个递归实例可向下深入递归两次，故属于多路递归中的二分递归。二分递归与此前介绍的线性递归有很大区别。比如，**在线性递归中整个计算过程仅出现一次递归基，而在二分递归过程中递归基的出现相当频繁，总体而言有超过半数的递归实例都是递归基。**

  * **效率**

    * 当然，并非所有问题都适宜于采用分治策略。实际上除了递归，此类算法的计算消耗主要来自两个方面。首先是**子问题划分**，即把原问题分解为形式相同、规模更小的多个子问题。其次是**子解答合并**，即由递归所得子问题的解，得到原问题的整体解，比如由子数组之和累加得到整个数组之和。

    * 为使分治策略真正有效，不仅必须保证**以上两方面的计算都能高效地实现**，还必须保证子问题之间相互独立。**各子问题可独立求解，而无需借助其它子问题的原始数据或中间结果**。否则，或者子问题之间必须传递数据，或者子问题之间需要相互调用，无论如何都会导致时间和空间复杂度的无谓增加。

    * Fibonacci数：二分递归示例

      ```c
      __int64 fib(int n)
      {
          return (n < 2) ? (__int64)n : fib(n-1) + fib(n-2);
      }
      ```

      ![20190213162802973](E:\Learn\repository\data-tructure\images\20190213162802973.png)

    * 基于Fibonacci数列原始定义的这一实现，不仅正确性一目了然，而且简洁自然。然而不幸的是，在这种场合采用二分递归策略的效率极其低下。实际上，该算法需要运行*O*(2^n)时间才能计算出第n个Fibonacci数。这一指数复杂度的算法，在实际环境中毫无价值。为确切地界定该算法的复杂度，不妨将计算fib(n)所需的时间记作T(n)。按该算法的思路，为计算出fib(n)，先花费T(n - 1)时间计算fib(n - 1)，再花费T(n - 2)时间计算fib(n - 2)，最后花费一个单位的时间将它们累加起来。

  * **优化策略**

    * 为消除递归算法中重复的递归实例，一种自然而然的思路和技巧，可以概括为：**借助一定量的辅助空间，在各子问题求解之后，及时记录下其对应的解答**

    * **可以从原问题出发自顶而下，每当遇到一个子问题，都首先查验它是否已经计算过，以期通过直接调阅记录获得解答，从而避免重新计算。也可以从递归基出发，自底而上递推地得出各子问题的解，直至最终原问题的解。前者即所谓的制表（tabulation）或记忆（memoization）策略，后者即所谓的动态规划（dynamic programming）策略。**

    * fib 优化

      ```c
      __int64 fib1(int n, __int64 &prev)
      {
          if (n == 0) {
              prev = 1; return 0;
          }
          __int64 preprev; prev = fib1(n-1, preprev);
          return prev + preprev;
      }
      ```

      ```c
      //计算Fibonacci数列癿第n项（迭代版）：O(n)
      __int64 fibI ( int n ) { 
          __int64 f = 0, g = 1; //初始化：fib(0)=0, fib(1) = 1
          while ( 0 < n-- ) { 
              g += f;
              f = g - f;
          } //依据原始定丿，通过n次加法和减法计算fib(n)
          return f; //迒回
      }
      ```

###### 递归分析

* 递归算法所需的计算时间，应该等于所有递归实例的创建、执行和销毁所需的时间总和。其中，递归实例的创建、销毁均由操作系统负责完成，其对应的时间成本通常可以近似为常数，不会超过递归实例中实质计算步骤所需的时间成本，故往往均予忽略。为便于估算，启动各实例的每一条递归调用语句所需的时间，也可以计入被创建的递归实例的账上，如此我们只需**统计各递归实例中非递归调用部分所需的时间**。
* **算法的空间复杂度在创建了最后一个递归实例（即到达递归基）时，占用的空间量达到最大。准确地说，等于所有递归实例各自所占空间量的总和。**

* **递归跟踪**
  * 作为一种直观且可视的方法，递归跟踪（recursion trace）可用以分析递归算法的总体运行时间与空间。具体地，就是按照以下原则，将递归算法的执行过程整理为图的形式：
    1. 算法的每一递归实例都表示为一个方框，其中注明了该实例调用的参数
    2. 若实例M调用实例N，则在M与N对应的方框之间添加一条有向联线
* **递推方程**
  * 递归算法的另一常用分析方法，即递推方程（recurrence equation）法。与递归跟踪分析相反，该方法无需绘出具体的调用过程，而是**通过对递归模式的数学归纳，导出复杂度定界函数的递推方程（组）及其边界条件**，从而**将复杂度的分析，转化为递归方程（组）的求解**。
  * 在总体思路上，该方法与微分方程法颇为相似：很多复杂函数的显式表示通常不易直接获得，但是它们的微分形式却往往遵循某些相对简洁的规律，通过求解描述这些规律的一组微分方程，即可最终导出原函数的显式表示。微分方程的解通常并不唯一，除非给定足够多的边界条件。类似地，为使复杂度定界函数的递推方程能够给出确定的解，也需要给定某些边界条件。以下我们将看到，这类边界条件往往可以通过对递归基的分析而获得。

###### 递归模式

* **多递归基**
  
* **为保证有穷性，递归算法都必须设置递归基，且确保总能执行到。**为此，针对每一类可能出 现的平凡情况，都需设置对应的递归基，故同一算法的递归基可能（显式或隐式地）不止一个。
  
* **实现递归**
  
  * 在设计递归算法时，往往需要从多个角度反复尝试，方能**确定对问题的输入及其规模的最佳划分方式**。有时，还可能**需要从不同的角度重新定义和描述原问题，使得经分解所得的子问题与原问题具有相同的语义形式**。
* **多向递归**
  
  * 递归算法中，不仅递归基可能有多个，递归调用也可能有多种可供选择的分支。以下的简单实例中，每一递归实例虽有多个可能的递归方向，但只能从中选择其一，故各层次上的递归实例依然构成一个线性次序关系，这种情况依然属于线性递归。(分析个算法的递归跟踪分析图的拓扑结构)
* **递归消除**
  * 按照递归的思想可使我们得以从宏观上理解和把握应用问题的实质，深入挖掘和洞悉算法过程的主要矛盾和一般性模式，并最终设计和编写出简洁优美且精确紧凑的算法。然而，递归模式并非十全十美，其众多优点的背后也隐含着某些代价。
    * **空间成本**
      * 从递归跟踪分析的角度不难看出，**递归算法所消耗的空间量主要取决于递归深度**。故较之同一算法的迭代版，递归版往往需耗费更多空间，并进而影响实际的运行速度。另外，就操作系统而言，为实现递归调用需要花费大量额外的时间以创建、维护和销毁各递归实例，这些也会令计算的负担雪上加霜。有鉴于此，在对运行速度要求极高、存储空间需精打细算的场合，往往应将递归算法改写成等价的非递归版本（一般的转换思路，无非是利用栈结构模拟操作系统的工作过程）。
* **尾递归及其消除**
  * 在线性递归算法中，若递归调用在递归实例中恰好以最后一步操作的形式出现，则称作尾递归
  * 实际上，属于尾递归形式的算法，均可以简捷地转换为等效的迭代版本。
  * 请注意，*尾递归的判断应依据对算法实际执行过程的分析，而不仅仅是算法外在的语法形式。*比如，**递归语句出现在代码体的最后一行，并不见得就是尾递归；严格地说，只有当该算法（除平凡递归基外）任一实例都终止于这一递归调用时，才属于尾递归。**

* 数组倒置分析

  * 借助线性递归不难解决这一问题，为此只需注意到并利用如下事实：为得到整个数组的倒置，可以先对换其首、末元素，然后递归地倒置除这两个元素以外的部分。

    ```c
    void swap(int *a, int *b)
    {
        int tmp = *a;
        *a = *b;
        *b = tmp;
    }
    void reverse(int * A, int lo, int hi)
    {
        if (lo < hi) {
            swap(A+lo, A+hi);
            reverse(A, lo+1, hi-1);
        }
         //else 隐含了两种递归基
    }
     //O(hi - lo + 1)
    ```

  * 代码中reverse(A, lo, hi)算法的最后一步操作，是对去除了首、末元素之后总长缩减两个单元的子数组进行递归倒置，即属于典型的尾递归。实际上，属于尾递归形式的算法，均可以简捷地转换为等效的迭代版本。

    ```c
    void reverse(int * A, int lo, int hi)
    {
        while (lo < hi) {
            swap(A+lo++, A+hi--);
        }
    }
    ```

##### 抽象数据类型

* 各种**数据结构都可看作是由若干数据项组成的集合，同时对数据项定义一组标准的操作**。现代数据结构普遍遵从“**信息隐藏**”的理念，通过**统一接口和内部封装，分层次从整体上加以设计、实现与使用**。
* 所谓**封装，就是将数据项与相关的操作结合为一个整体，并将其从外部的可见性划分为若干级别，从而将数据结构的外部特性与其内部实现相分离，提供一致且标准的对外接口，隐藏内部的实现细节**。于是，*数据集合及其对应的操作可超脱于具体的程序设计语言、具体的实现方式*，即构成所谓的抽象数据类型（abstract data type, ADT）。

* 抽象数据类型的理论催生了现代面向对象的程序设计语言，而支持封装也是此类语言的基本特征。