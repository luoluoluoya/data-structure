

#### 排序的基本概念与分类

* 假设含有 n 个记录的序列为 $r_1,r_2,r_3,...,r_n$,其相应的关键字分别为如 $k_1,k_2,k_3,...,k_n$,需确定$r_1,r_2,r_3,...,r_n$的一种排列$p_1,p_2,p_3,...,p_n$, 使其相应的关键字满足$$k_{p1} \le k_{p2} \le k_{p 3}  \le ...  \le  k_{pn}$$（非递减或非递增）关系，即使得序列成为一个按关键字有序的序列 $$r_{p1}, r_{p2}, r_{p 3}, ...  , r_{pn}$$,这样的操作就称为排序。
  * 在排序问题中，通常将数据元素称为记录。显然我们输入的是一个记录集合，输岀的也是一个记录集合，所以说，可以将排序看成是线性表的一种操作。
  * 排序的依据是关键字之间的大小关系，那么，对同一个记录集合，针对不同的关键字进行排序，可以得到不同序列。
  * 关键字虹可以是记录r的主关键字，也可以是次关键字，甚至是若干数据项 的组合。
  * 多个关键字的排序最终都可以转化为单个关键字的排序, 因此，我们这里主要讨论的是单个关键字的排序。
* 由于排序不仅是针对主关键字，那么对于次关键字，因为待排序的记录序 列中可能存在两个或两个以上的关键字相等的记录，排序结果可能会存在不唯一的情 况
* 排序的稳定性
  * 假设 $k_i = k_j (1 \le i \le n, 1 \le j \le n, i\neq j)$ . 且在排序前的序列中$r_i$领先于$r_j$（即$i \le j$)。 如果排序后$r_i$仍领先于$r_j$则称所用的排序方法是稳定的；反之，若可能使得排序后的序列中$r_j$领先$r_i$则称所用的排序方法是不稳定的
    * 只要有一组关键字实例发生类似情况， 就可认为此排序方法是不稳定的。
    * 排序算法是否稳定的，要通过分析后才能得出。
* 内排序与外排序
  * 根据在排序过程中待排序的记录是否全部被放置在内存中，排序分为：内排序和 外排序。
  * 内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中。外排序是 由于排序的记录个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多 次交换数据才能进行。
* 排序算法的性能
  * 时间性能
    * 排序是数据处理中经常执行的一种操作，往往属于系统的核心部分，因此排序算 法的时间开销是衡量其好坏的最重要的标志。在内排序中，主要进行两种操作：比较 和移动。比较指关键字之间的比较，这是要做排序最起码的操作。移动指记录从一个 位置移动到另一个位置，事实上，移动可以通过改变记录的存储方式来予以避免（这 个我们在讲解具体的算法时再谈）。总之，高效率的内排序算法应该是具有尽可能少的 关键字比较次数和尽可能少的记录移动次数。
  *  辅助空间
    * 评价排序算法的另一个主要标准是执行算法所需要的辅助存储空间。辅助存储空 间是除了存放待排序所占用的存储空间之外，执行算法所需要的其他存储空间。
  * 算法的复杂性
    * 注意这里指的是算法本身的复杂度，而不是指算法的时间复杂度。显然算法过于 复杂也会影响排序的性能。

* 排序用到的结构与函数

  * 顺序表结构

    ```
    #define MAXSIZE 10	/*用于要排序数组个数最大值，可根据需要修改*/
    typedef struct
    {
      int r[MAXSIZE+l]; /*用于存储要排序教組，r[0] 用作哨兵或临时变量*/ 
      int length;	/*用于记录顺序表的长度*/
    } SqList;
    
    /*另外，由于排序最最常用到的操作是数组两元素的交换，我们将它写成函数，在之后的讲解中会大量的用到。*/
    
    /*交换L中数组工的下标为i和j的值*/
    void swap ( SqList *L, int i, int j )
    (
      int temp = L->r[i];
      L->r[i] = L->r[j];
      L->r[j] = temp;
    }
    ```

---

#### 冒泡排序

* 简单排序实现: 冒泡排序(Bubble Sort)一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。(逆序对)

* 冒泡排序算法实现

  ```
  
  ```

* 冒泡排序优化

  * 当某次遍历没有任何数据交换，这就说明此序列已经有序，不需要再继续后面的循环判断工作了，可以避免因已经有序的情况下的无意义循环判断。

* 冒泡排序优化算法实现

  ```
  
  ```

* 冒泡排序复杂度分析
  
  * 当最好的情况，也就是要排序的表本身就是有序的， 那么我们比较次数，根据最后改进的代码，可以推断出就是 n-1次的比较，没有数据交换，时间复杂度为O(n)。当最坏的情况，即待排序表是逆序的情况，此时需要比较了$\sum _{i=2}^n {n-i} = (n-1)+...+3+2+1 = n(n-1)/2$次，并作等数量级的记录移动。因此，总的时间复杂度为 O(n^2)。

---

#### 简单选择排序

* 冒泡排序的思想就是不断地在交换，通过交换完成最终的排序。我们可不可以在排序时找到合适的关键字再做交换，并且只移动一次就完成相应关键字的排序定位工作。

* 选择排序的基本思想是每一趟在 n-1+1 (i = 1,2,...,n-1) 个记录中选取关键字最小的记录作为有序序列的第 i 个记录。

* 简单选择排序法(Simple Selection Sort) 就是通过 n-i 次关键字间的比较，从 n-i+1 个记录中选出关键字最小的记录，并和第 i (1 <= i <= n)个记录交换之。

* 简单选择排序法算法实现

  ```
  
  ```

* 简单选择排序复杂度分析
  
  * 从简单选择排序的过程来看，它最大的特点就是交换移动数据次数相当少，这样也就节约了相应的时间。分析它的时间复杂度发现，无论最好最差的情况，其比较次数都是一样的多，第 i 趟排序需要进行 n-i 次关键字的比较,此时需要比较 $\sum _{i=1}^{n-1}(n-i) = n-1 + n-2 + ... + 1 = n(n-1)/2$次。而对于交换次数而言，当最好的时候，换为0次，最差的时候，也就初始降序时，交换次数为 n-1 次，基于最终的排序时间 是比较与交换的次数总和，因此，总的时间复杂度依然为0(n^2)。应该说，尽管与冒泡排序同为0(n^2)，但简单选择排序的性能上还是要略优于冒泡排序。

---

#### 直接插入排序

* 直接插入排序(Straight Insertion Sort)的基本操作是将一个记录插入到已经排好序的有序表中，从而得到一个新的、记录数增1的有序表。

* 算法实现

  ```
  /*利用哨兵*/
  ```

* 直接插入排序复杂度分析
  * 分析一下这个算法，从空间上来看，它只需要一个记录的辅助空间，因此关键是看它的时间复杂度。
  * 当最好的情况，也就是要排序的表本身就是有序的，比如 {2,3,4,5,6}, 那么我们比较次数，其实就是代码每个 L[i] 与 L[i-1] 的比较， 共比较了 n-1 次，由于每次都是 L[i] > L[i-1], 因此没有移动的记录，时间复杂度为O(n).
  * 当最坏的情况，即待排序表是逆序的情况，比如{6,5,4,3,2}, 此时需要比较$\sum_{i=2}^ni = 2 + 3 + ... + n = (n+2)(n-1)/2$次，而记录的移动次数也达到最大值 $\sum_{i=2}^n{i+1} = (n+4)(n-1)/2$次。
  * 如果排序记录是随机的，那么根据概率相同的原则，平均比较和移动次数约为 n^2/4 次。因此，我们得出直接插入排序法的时间复杂度为O(n^2)。从这里也看出，同样的 O(n^2) 时间复杂度，直接插入排序法比冒泡和简单选择排序的性能要好一些。

---

#### 希尔排序

* 希尔排序是D.LShell于1959年 提出来的一种排序算法，在这之前排序算法的时间复杂度基本都是0(n^2)的，希尔排 序算法是突破这个时间复杂度的第一批算法之一。

* 直接插入排序，它的效率在某些时候是很高的，比如， 我们的记录本身就是基本有序的，我们只需要少量的插入操作，就可以完成整个记录 集的排序工作，此时直接插入很高效。还有就是记录数比较少时，直接插入的优势也 比较明显。可问题在于，两个条件本身就过于苛刻，现实中记录少或者基本有序都属 于特殊情况。

  * 元素基本有序
  * 元素基数较少

* 如何让待排序的记录个数较少呢

  * 很容易想到的就是将原本有大量记录数的记录 进行分组。分割成若干个子序列，此时每个子序列待排序的记录个数就比较少了，然 后在这些子序列内分别进行直接插入排序，当整个序列都基本有序时，注意只是基本有序时，再对全体记录进行一次直接插入排序。
  * 所谓的基本有序，就是小的关键字基本在前面，大的基本在后面，不大不小 的基本在中间，像{2,1,3,6,4,7,589}这样可以称为基本有序了。但像{1,5,9,3,7,8,2,4,6} 这样的9在第三位，2在倒数第三位就谈不上基本有序。
    * 小元素大体在前面， 大元素大体在后面

* 我们分割待排序记录的目的是减少待排序记录的个数，并 使整个序列向基本有序发展。我们需要采取跳跃分割的策略：将相距某个“增量”的记录组成一个子序列，这样才能保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不 是局部有序。

  * 增量为 1 时，所有元素都分配到一个子序列中。（对所有元素执行插入排序）
  * 对每个子序列执行插入排序并非各自独立完成，而是交替执行

* 算法实现

  ```
  *对顺序表L作希尔排序•/
  1void ShellSort (SqList *L )
  2(
  3int i/j;
  4int increment=L->length;
  5do
  6(
  7increment=increment/3+l；	/* 增量序列 */
  8for (i=increment+l;i<=L->length;i++ )
  9I
  10if (L->r[i]<L->r[i-increment])
  11{/*需将L->r[i]插入有序増量子;t */
  12L->r[0]-L->r[i];	/* 暂存在 L->r[0] */
  13for (j-i-increment;j>0&&L->r[0]<L->r[j];j-«=increment)
  14L->r [ j+increment] =L->r [ j ]; / *记录后移，查找插入位置 */
  15L->r [ j+increment] =L->r [0] ; /* 插入 */
  16)
  17}
  18}
  19while ( increment>l);
  20}
  ```

  ```
  void ShellSort (SqList *L)
  {
  	int i,j;
  	int incr = L->length;
  	do {
  		incr = incr / 3 + 1; /*相隔 3 作为子序列*/
  		for (i = incr + 1; i < L->length; i++) {
  			if (L->r[i] < L->r[i-incr]) {
  				L->r[0] = L->r[i];  /*设置哨兵*/
  				/*在当前子序列内执行插入排序*/
  				for (j = i - incr; j>0 && L->r[o] < L->r[j]; j-=incr) {
  					L->r[j+incr] = L->r[0];
  				}
  				L->r[j+incr] = L->r[0];
  			}
  		}
  	} while(incr > 1);
  }
  ```

  

* 希尔排序的关键并不是随便分组后各自排序，而是将相隔某个“增量”的记录组成一个子序列，实现跳跃式的移动，使得 排序的效率提高。这里“增量'‘的选取就非常关键了。可究竟应该选取什么样的增量才是最好，目前还 是一个数学难题，迄今为止还没有人找到一种最好的增量序列。需要注意的是，增量序列的最后一个增量值必须等于1才行。另外由于记录是跳跃式的移动，希尔排序并不是一 种稳定的排序算法。
* 希尔排序的复杂度和增量序列是相关的
  * {1,2,4,8,...}这种序列并不是很好的增量序列，使用这个增量序列的时间复杂度（最坏情形）是O(n^2)
  * Hibbard提出了另一个增量序列{1,3,7，...,2^k-1}，这种序列的时间复杂度(最坏情形)为O(n^1.5)
  * Sedgewick提出了几种增量序列，其最坏情形运行时间为O（n^1.3）,其中最好的一个序列是{1,5,19,41,109,...}

---

#### 堆排序

* 简单选择排序，它在待排序的 n 个记录中选择一个最小的记录需要 比较 n-1 次。本来这也可以理解，查找第一个数据需要比较这么多次是正常的，否则如何知道它是最小的记录。可惜的是，这样的操作并没有把每一趟的比较结果保存下来，在后一趟的比较 中，有许多比较在前一趟已经做过了，但由于前一趟排序时未保存这些比较结果，所以后一趟排序时又重复执行了这些比较操作，因而记录的比较次数较多。如果可以做到每次在选择到最小记录的同时，并根据比较结果对其他记录做出相 应的调整，那样排序的总体效率就会非常高了。而堆排序（Heap Sort）,就是对简单选择排序进行的一种改进，这种改进的效果是非常明显的。堆排序算法是Fbyd和 Williams在1964年共同发明的，同时，他们发明了 “堆”这样的数据结构。

* 堆是具有下列性质的完全二叉树：

  * 每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆
  * 每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆

* 从堆的定义可知，根结点一定是堆中所有结点最大（小）者。较大 （小）的结点靠近根结点（但也不绝对）

* 如果按照层序遍历的方式给结点从1开始编号，则结点之间满足如下关系
  $$
  \begin{cases}
  k_i \ge k_{2i} \\ 
  k_i \ge k_{2i+1}
  \end{cases}
  或者
  \begin{cases}
  k_i \le k_{2i} \\ 
  k_i \le k_{2i+1}
  \end{cases}
  
  1\le i \le \lfloor n/2 \rfloor
  $$

* 一棵完全二叉树，如果 i=1, 则结点 i  是二叉树的根，无双亲；如果 i>l, 则其双亲是结点 $\lfloor i/2 \rfloor$那么对于有n个结点的二 叉树而言，它的i值自然就是小于等于$\lfloor n/2 \rfloor$.

* 堆排序（Heap Sort）就是利用堆（假设利用大顶堆）进行排序的方法。它的基本思想是，将待排序的序列构造成一个大顶堆。此时，整个序列的最大值就是堆顶的根结点。将它移走（其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值），然后将剩余的 n-1个序列重新构造成一个堆，这样就会得到n个元素中的次大值。如此反复执行，便能得到一个有序序列了。

  * 将现在的待排序序列构建成一个大顶堆
    * 待排序的序列构建成为一个大顶堆，其实就是从下往上、从右到 左，将每个非终端结点（非叶结点）当作根结点，将其和其子树调整成大顶堆。
  * 逐步将每个最大值的根结点与末尾元素交换，并且再调整其成为大顶堆。

* 关键问题

  * 如何由一个无序序列构建成一个堆
  * 如果在输出堆顶元素后，调整剩余元素成为一个新的堆

* 算法实现

  ```
  
  ```

* 堆排序复杂度分析
  * 它的运行时间主要是消耗在初始构建堆和在重建堆时的反复筛选上。
  * 在构建堆的过程中，因为我们是完全二叉树从最下层最右边的非终端结点开始构 建，将它与其孩子进行比较和若有必要的互换，对于每个非终端结点来说，其实最多进行两次比较和互换操作，因此整个构建堆的时间复杂度为O(n)。
    * 由下至上，由右至左选取非叶子节点来调用adjusthead()函数。那么倒数第二层的最右边的非叶子节点就是最后一个非叶子结点。假设高度为k，则从倒数第二层右边的节点开始，这一层的节点都要执行子节点比较然后交换（如果顺序是对的就不用交换）；倒数第三层呢，则会选择其子节点进行比较和交换，如果没交换就可以不用再执行下去了。如果交换了，那么又要选择一支子树进行比较和交换；高层也是这样逐渐递归。那么总的时间计算为：s = 2^( i - 1 ) * ( k - i )；其中 i 表示第几层，2^( i - 1) 表示该层上有多少个元素，( k - i) 表示子树上要下调比较的次数。S = 2^(k-2) * 1 + 2^(k-3)2…..+2(k-2)+2^(0)*(k-1) ===> 因为叶子层不用交换，所以 i从 k-1 开始到 1；S = 2^k -k -1；又因为k为完全二叉树的深度，而log(n) =k，把此式带入；得到：S = n - log(n) -1，所以时间复杂度为：O(n)
  * 在正式排序时，第i次取堆顶记录重建堆需要O(logn)的时间（完全二叉树的某 个结点到根结点的距离为$log_2i+1$）,并且需要取n-1次堆顶记录，因此，重建堆 的时间复杂度为O(nlogn)。
    * 在取出堆顶点放到对应位置并把原堆的最后一个节点填充到堆顶点之后，需要对堆进行重建，只需要对堆的顶点调用adjustheap()函数。每次重建意味着有一个节点出堆，所以需要将堆的容量减一。adjustheap()函数的时间复杂度k=log(n)，k为堆的层数。所以在每次重建时，随着堆的容量的减小，层数会下降，函数时间复杂度会变化。重建堆一共需要n-1次循环，每次循环的比较次数为log(i)，则相加为：log2+log3+…+log(n-1)+log(n)≈log(n!)。可以证明log(n!)和nlog(n)是同阶函数, 所以时间复杂度为O(nlogn)
  * 总体来说，堆排序的时间复杂度为O(nlogn). 由于堆排序对原始记录的排序状态并不敏感，因此它无论是最好、最坏和平均时间复杂度均为O(nlogn). 这在性能 上显然要远远好过于冒泡、简单选择、直接插入的O(n^2)的时间复杂度了。空间复杂度上, 它只有一个用来交换的暂存单元，也非常的不错。不过由于记录的比较与交换是跳跃式进行,因此堆排序也是一种不稳定的排序方法。另外，由于初始构建堆所需的比较次数较多，因此，它并不适合待排序序列个数较少的情况.
    * 初始化建堆的时间复杂度为O(n)，排序重建堆的时间复杂度为nlog(n)，所以总的时间复杂度为O(n+nlogn)=O(nlogn)。另外堆排序的比较次数和序列的初始状态有关，但只是在序列初始状态为堆的情况下比较次数显著减少，在序列有序或逆序的情况下比较次数不会发生明显变化。

---

#### 归并排序

* "归并" 一词的中文含义就是合并、并入的意思，而在数据结构中的定义是将两个 或两个以上的有序表组合成一个新的有序表。

* 归并排序(Merging Sort)就是利用归并的思想实现的排序方法。它的原理是假设初始序列含有 n 个记录，则可以看成是 n 个有序x的子序列，每个子序列的长度为 1,然后两两归并，得到 $\lceil n/2 \rceil$ ($\lceil x \rceil$表示不小于x的最小整数) 个长度为2或1的有 序子序列；再两两归并，……,如此重复，直至得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序。

* **归并排序实现时常需要用到递归调用，因此我们可以外封装一个函数。**

* 递归版算法实现

  ```c
  
  ```

* 非递归版算法实现

  * 归并排序大量引用了递归，尽管在代码上比 较清晰，容易理解，但这会造成时间和空间上的性能损耗。
  * 非递归的迭代方法，避免了递归时深度为 logn 的栈空间，空间只是用到申请归并临时用的TR数组，因此空间复杂度为0(n)，并且避免递归也在时间性能上有一定的 提升，应该说，使用归并排序时，尽量考虑用非递归方法。

  ```
  
  ```

* 归并排序复杂度分析
  * 我们来分析一下归并排序的时间复杂度，一趟归并需要将 SR[1] ~ SR[n] 中相邻的长度为 h 的有序序列进行两两归并。并将结果放到TR[1] ~ TR[n]​]中，这需要将待排序序列中的所有记录扫描一遍，因此耗费 O (n) 时间，而由完全二叉树的深度可知，整 个归并排序需要进行 O(logn) 次，因此，总的时间复杂度为 O(nlogn)，而且这是归并排 序算法中最好、最坏、平均的时间性能。
  * 由于归并排序在归并过程中需要与原始记录序列同样数量的存储空间存放归并结果以及递归时深度为 logn 的栈空间，因此空间复杂度为 O(n+logn). 另外，对代码进行仔细研究，发现Merge函数中需要两两比较，不存在跳跃，因此归并排序是一种稳定的排序算法。也就是说，归并排序是一种比较占用内存，但却效率高且稳定的算法。

---

#### 快速排序

* 希尔排序相当于直接插入排序的升级，它们同属于**插入排序类**，堆排序相当于简单选择排序的升级，它们同属于**选择排序类**。而快速排序其实就是我们前面认为最慢的冒泡排序的升级，它们都属于**交换排序类**。即它也是通过不断比较和移动交换来实现排序的，只不过它的实现，增大了记录的比较和移动的距离，将关键字较大的记录 从前面直接移动到后面，关键字较小的记录从后面直接移动到前面，从而减少了总的 比较次数和移动交换次数。
* 快速排序(Quick Sort)的基本思想是：通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部 分记录继续进行排序，以达到整个序列有序的目的。
  * 选取当中的一个关键 字，然后想尽办法将它放到一个位置，使得它左边的值都 比它小，右边的值比它大，我们将这样的关键字称为**枢轴(Pivot)**.
  * Partition函数，其实就是将选取的 pivotkey 不断交换，将比它小的换到它的左边，比它大的换到它的右边，它也在交换中不断更改自己的位置，直到完全满足这个要求为止。
* 快速排序复杂度分析
* 

