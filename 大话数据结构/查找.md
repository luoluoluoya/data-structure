##### 查找概论

* **查找**   查找(Searching)就是根据给定的某个值，在查找表中确定一个其关键字等 于给定值的数据元素(或记录)。
  * 查找表（Search Table）是由同一类型的数据元素（或记录）构成的集合。
  * 关键字（Key）是数据元素中某个数据项的值，又称为键值，用它可以标识一个数据元素。也可以标识一个记录的某个数据项（字段），我们称为关键码.
  * 此关键字可以唯一地标识一个记录，则称此关键字为主关键字（Primary Key）. 注意这也就意味着，对不同的记录，其主关键字均不相同。主关键字所在的数据项称为主关键码.
  * 对于那些可以识别多个数据元素（或记录）的关键字，我们称为次关键字（Secondary Key）。次关键字也可以理解为是不以唯一标识一个 数据元素（或记录）的关键字，它对应的数据项就是次关键码。
* 若表中存在这样的一个记录，则称查找是成功的，此时查找的结果给出整个记录 的信息，或指示该记录在查找表中的位置。若表中不存在关键字等于给定值的记录，则称查找不成功，此时查找的结果可给 出一个“空”记录或“空”指针。
* 静态査找表（Static Search Table）:只作査找操作的查找表。它的主要操作有：
  * 查询某个 “特定的” 数据元素是否在查找表中。
  * 检索某个 “特定的” 数据元素和各种属性。
* 动态査找表(Dynamic Search Table): 在査找过程中同时插入査找表中不存在的 数据元素，或者从査找表中删除已经存在的某个数据元素。显然动态查找表的操作就 是两个：
  * 查找时插入数据元素。
  * 查找时删除数据元素。
* 为了提高査找的效率，我们需要专门为查找操作设置数据结构，这种面向查找操 作的数据结构称为**查找结构**。
  * 从逻辑上来说，查找所基于的数据结构是集合，集合中的记录之间没有本质关系。
  * 可是要想获得较高的查找性能，我们就不能不改变数据元素之间的关系，在存储时可以将查找集合组织成表、树等结构。例如，对于静态查找表来说，我们不妨应用线性表结构来组织数据，这样可以使用顺序査找算法，如果再对主关键字排序，则可以应用折半查找等技术进行高效的查找。如果是需要动态查找，则会复杂一些，可以考虑二叉排序树的查找技术。

---

##### 顺序表查找

* **顺序査找(Sequential Search)**   又叫线性査找，是最基本的查找技术，它的査找过程是：从表中第一个(或最后一个)记录开始，逐个进行记录的关键字和给定值比较，若某个记录的关键字和给定值相等，则查找成功，找到所查的记录；如果直到最 后一个(或第一个)记录，其关键字和给定值比较都不等时，则表中没有所查的记 录，查找不成功。

* 顺序查找的算法实现

  ```c
  /* 顺序查找，a为数组，n为要查找的数组个数，key为要查找的关键字*/
  int SequentialSearch (int *a, int n, int key)
  {
      int i;
      for (i=l;i<=n;i++)
      {
          if (a[i] == key)
              return i;
      }
      return 0;
  }
  ```
  * 每次循环时都需要对 i 是否越界，即是否小于等于n 作判断。事实上，还可以有更好一点的办法，设置一个哨兵，可以解决不需要每次让 i  与 n 作比较。

* 顺序表查找优化

  ```
  /*有哨兵顺序查找*/
  int SequentialSearch2 （int *a,int n,int key）
  {
      int i;
      a[O]=key; /*设置a[O]为关键字值，我们称之为“哨兵” */
      i=n;	/*循环从数组尾部开始*/
      while （ a[i] != key ）
      {
      	i--;
      }
      return i; /*返回0则说明查找失败*/
  }
  ```

  * 在查找方向的尽头放置“哨兵”免去了在查找过程中每一次比较后都要判断查找位置是否越界的小技巧，看似与原先差别不大，但在总数据较多时，效率提高很大，是非常好的编码技巧。当然，“哨兵”也不一定就一定要在数组开始，也可以在末端。

* 对于这种顺序查找算法来说，查找成功最好的情况就是在第一个位置就找到了， 算法时间复杂度为 O(1) ,最坏的情况是在最后一位置才找到，需要n次比较，时间复 杂度为 O(n) ，当查找不成功时，需要n+1次比较，时间复杂度为 O(n+1). 我们之前推 导过，关键字在任何一位置的概率是相同的，所以平均查找次数为 O((n+1)/2) ,所以最终 时间复杂度还是 O(n)。

* 很显然，顺序查找技术是有很大缺点的，n 很大时，查找效率极为低下，不过优 点也是有的，这个算法非常简单，对静态查找表的记录没有任何要求，在一些小型数 据的查找时，是可以适用的。另外，也正由于査找概率的不同，我们完全可以**将容易查找到的记录放在前面， 而不常用的记录放置在后面，效率就可以有大幅提高。**

---

##### 有序表查找

* 一个线性表有序时，对于查找总是很有帮助的。

###### 折半査找（Binary Search）技术

* 又称为二分査找。它的**前提是线性表中的记录必须是关键码有序**（通常从小到大有序），**线性表必须采用顺序存储**。折半査找的基 本思想是：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键字相等，则査找成功；若给定值小于中间记录的关键字，则在中间记录的左半区继续査 找；若给定值大于中间记录的关键字，则在中间记录的右半区继续査找。不断重复上述过程，直到査找成功，或所有查找区域无记录，査找失败为止。

* 折半査找算法实现

  ```c
  /*折半查找*/
  int Binary_Search (int *a, int n, int key)
      int low,high,mid;	
      low=l;	/*定义最低下标为记录首位*/
      high=n;	/*定义最高下标为记录末位*/
      
      while (low<=high )	
      {	
          mid = (low+high)/2		/* 折半 */
          if ( key < a[mid]	)	/*若查找值比中值小*/
          	high = mid-l;	/*最高下标调整到中位下标小一位*/
          else if ( key >a[mid] )	/*若查找值比中值大*/
          	low=mid+l;	/*最低下标调整到中位下标大一位*/
          else	
          	return mid;	/*若相等则说明 mid 即为查找到的位置 */
      }	
  	return 0;	
  }	
  ```
  * 折半査找是一个基于二元比较的决策树， 树叶对应于一个求解结果。每个内部节点对应于一次决策（二元比较）。算法的复杂度 = 求解问题所需的决策次数，即从跟到叶节点的高度。
  * 折半算法的时间复杂度为 O(logn)，它显然远远好于顺序查找的 0(n)  时间复杂度.
  * 由于折半查找的前提条件是需要有序表顺序存储，对于静态查找表，一次排 序后不再变化，这样的算法已经比较好了。但对于需要频繁执行插入或删除操作的数据集来说，维护有序的排序会带来不小的工作量，那就不建议使用。

###### 插值查找

* 示例： 要在取值范围。5 ~ 10000之间100个元素从小到大均匀分布的数组中查找5, 我们自然会考虑从数组下标较小的开始查找。

* 对折半查找的查找划分进行改进
  $$
  mid = \tfrac {low + high} {2} = low + \tfrac{1}{2}(high - low)
  $$
  也就是 mid 等于最低下标 low 加上最髙下标 high 与 low 的差的一半。算法科学家们考虑的就是将这个 1/2 进行改进，改进为下面的计算方案：
  $$
  mid = low + \tfrac{key - a[low]}{a[high] - a[low]}(high - low)
  $$

* 插值査找(InterpoMon Search)是根据要査找的关键字key与査找表中最大最小记录的关键字比较后的査找方法，其核心插值的计算公式。应该说， 从时间复杂度来看， 它也是 O(logn)的。 但**对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好得多**。反之，数组中如果分布类似｛0,1,2,2000,2001, 999998, 999999)这种极端不均匀的数据，用插值查找未必是很合适的选择。
* 折半查找是从中间分，也就是说，每一次查找总是一分 为二，无论数据偏大还是偏小，很多时候这都未必就是最合理的做法。除了插值查找，我们再介绍一种有序查找，斐波那契查找(Fibonacci Search),它是利用了黄金分割原理来实现的。

###### 斐波那契查找

*  斐波那契查找就是在二分查找的基础上根据斐波那契数列进行分割的。在斐波那契数列找一个等于略大于查找表中元素个数的数F[n]，将原查找表扩展为长度为$F[n]$(如果要补充元素，则补充重复最后一个元素，直到满足F[n]个元素)，完成后进行斐波那契分割，即F[n]个元素分割为前半部分F[n-1]个元素，后半部分F[n-2]个元素，找出要查找的元素在那一部分并递归，直到找到。
* 斐波那契查找的时间复杂度还是O(log 2 n )，但是 与折半查找相比，斐波那契查找的优点是它只涉及加法和减法运算，而不用除法，而除法比加减法要占用更多的时间，因此，斐波那契查找的运行时间理论上比折半查找小，但是还是得视具体情况而定。
* 每次取斐波那契数列中的某个值时(F[k])，都会进行-1操作，这是因为有序表数组位序从0开始的，纯粹是为了迎合位序从0开始。

* 算法实现

  ```
  /*斐波那契查找*/	
  int FibonacciSearch (int *a, int n, int key)
  {
      int low,high,mid,i,k;	
      low=l;	/*定义最低下标为记录首位*/
      high=n;	/*定义最高下标为记录末位*/
      k=0;	
      
      /*计算 n 位于斐波那契数列的位置*/
      while ( n > F[k] -1 )	
          k++;
          
      /*将不满的数值补全*/
      for (i=n; i<F[k]-l;i++)
          a[i]=a[n]；	
          
      while (low <= high)	
      {
          mid = low + F[k-1] -1;	/*计算当前分隔的下标*/
          if (key<a[mid]) 	/*若查找记录小于当前分隔记录*/
          {
              high=mid-l;	/*最高下标调祭到分隔下标mid-1处*/
              k = k-l;	/*斐波那奖数列下标减一位*/
          }	
      	else if ( key>a[mid] ) /*若查找记录大于当前分隔记录*/
      	{
              low=mid+l;	/*	最低下标调签到分割下标mid+1处*/
              k = k-2; /*	斐波那契數列下标减两位*/
          }
          else
          {
              if (mid <= n)		
              	return mid;	 /*若相等则说明mid即为查找到的位置*/
              else		
              	return n;	 /*若mid>n说明是补全數位，返回n */
          }
      }
     	return 0;
  }
  /* F[k] = F[k-1] + F[k-2] */
  /**/
  ```

* 斐波那契查找算法的核心在于：

  * 当 key=a[mid] 时，查找就成功；

  * 当 key<a[mid] 时，新范围是第 low 个到第 mid-1 个，此时范围个数为F[k-1]  - 1个；

  * 当 key>a[mid], 新范围是第 m+1个到第high个，此时范围个数为 F[k-2] - 1个。

  ![image-20200425180859708](C:\Users\47302\AppData\Roaming\Typora\typora-user-images\image-20200425180859708.png)

* 如果要查找的记录在右侧，则左侧的数据都不用再判断了，不断反复进行下去，对处于当中的大部分数据，其工作效率要高一些。所以尽管斐波那契查找 的时间复杂也为0(logn),但就平均性能来说，斐波那契查找要优于折半查找。可惜如果是最坏情况，比如 key 始终都处于左侧长半区在查找，则查找效率要低于折半査找。

---

##### 线性索引查找

* 数据结构的最终目的是提高数据的处理速度，索引是为了加快查找速度而设计的 —种数据结构。索引就是把一个关键字与它对应的记录相关联的过程，一个索引由若干个索引项构成，每个索引项至少应包含关键字和其对应的记录在存储器中的位置等信息。索引技术是组织大型数据库以及磁盘文件的一种重要技术。
* 索引按照结构可以分为线性索引、树形索引和多级索引。我们这里就只介绍线性 索引技术。所谓线性索引就是将索引项集合组织为线性结构，也称为索引表。我们重点介绍三种线性索引：稠密索引、分块索引和倒排索引。

###### 稠密索引

* 稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项。
* 对于稠密索引这个索引表来说，索引项一定是按照关键码有序的排列。索引项有序也就意味着，我们要查找关键字时，可以用到折半、插值、斐波那契等有序查找算法，大大提高了效率。这显然是稠密索引优点，但是如果数据集非常大，比如上亿，那也就意味着索引 也得同样的数据集长度规模，对于内存有限的计算机来说，可能就需要反复去访问磁 盘，查找性能反而大大下降了。

###### 分块索引

* 稠密索引因为索引项与数据集的记录个数相同，所以空间代价很大。为了减少索 引项的个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。
* **分块有序**，是把数据集的记录分成了若干块，并且这些块需要满足两个条件
  * **块内无序**，即每一块内的记录不要求有序。当然，你如果能够让块内有序对查找来说更理想，不过这就要付出大量时间和空间的代价，因此通常我们不要求块内有序。
  * **块间有序**，例如，要求第二块所有记录的关键字均要大于第一块中所有记录的关键字，第三块的所有记录的关键字均要大于第二块的所有记录关键字...,因为只有块间有序，才有可能在查找时带来效率。
* 对于分块有序的数据集，将每块对应一个索引项，这种索引方法叫做**分块索引**。
* 定义的分块索引的索引项结构分三个数据项
  * **最大关键码**，它存储每一块中的最大关键字，这样的好处就是可以使得在 它之后的下一块中的最小关键字也能比这一块最大的关键字要大
  * 存储了**块中的记录个数**，以便于循环时使用；
  * 用于**指向块首数据元素的指针**，便于开始对这一块中记录进行遍历。

* 在分块索引表中查找，就是分两步进行

  * **在分块索引表中查找要查关键字所在的块**。由于分块索引表是块间有序的， 因此很容易利用折半、插值等算法得到结果。
  * 根据块首指针找到相应的块，并**在块中顺序查找关键码**。因为块中可以是无序 的，因此只能顺序查找。

* 分块索引的性能分析

  * 分析一下分块索引的平均查找长度。设 n 个记录的数据集被平均分成 m 块，每个块中有 t 条记录，显然 n=m*t, 或者说 m=n/t 。再假设$L_b$为查找索引表的平均查找长度，因最好与最差的等概率原则，所以Lb的平均长度为(m+1)/2。$L_w$为块中 查找记录的平均査找长度，同理可知它的平均查找长度为(t+1)/2。这样分块索引查找的平均查找长度为：
    $$
    ASL_w = L_b + L_w = \tfrac{m+1}{2} + \tfrac{t+1}{2} = 1/2(m+t)+1 = 1/2(\tfrac{n}{t}+t)+1
    $$
    注意上面这个式子的推导是为了让整个分块索引查找长度依赖 n 和 t 两个变量。 从这里了我们也就得到，平均长度不仅仅取决于数据集的总记录数 n,还和每一个块 的记录个数 t 相关。最佳的情况就是分的块数 m 与块中的记录数 t 相同，此时意味着 n = m * t = t^2,即
    $$
    ASL_w = 1/2(\tfrac{n}{t} + t) + 1 = \sqrt{n} + 1
    $$
    可见，分块索引的效率比之顺序查找的 O(n) 是高了不少，不过显然它与折半查找 的 O(logn) 相比还有不小的差距。因此在确定所在块的过程中，由于块间有序，所以可 以应用折半、插值等手段来提高效率。总的来说，分块索引在兼顾了对细分块不需要有序的情况下，大大增加了整体查 找的速度，所以普遍被用于数据库表查找等技术的应用当中。

###### 倒排索引

* 索引项的通用结构是：
  * 次关键码  
  * 记录号表
* 记录号表存储具有相同次关键字的所有记录的记录号（可以是指向记录的指针或者是该记录的主关键字）。这样的索引方法就是倒排索引（inverted index）。倒排索引源于实际应用中需要根据属性（或字段、次关键码）的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引。
* 倒排索引的优点显然就是查找记录非常快，基本等于生成索引表后，查找时都不 用去读取记录，就可以得到结果。但它的缺点是这个记录号不定长，维护比较困难，插入和删除操作都需要作相应的处理。

---

##### 二叉排序树

* 假设查找的数据集是普通的顺序存储，那么插入操作就是将记录放在表的末端， 给表记录数加一即可，删除操作可以是删除后，后面的记录向前移，也可以是要删除的元素与最后一个元素互换，表记录数减一，反正整个数据集也没有什么顺序，这样 的效率也不错。应该说，插入和删除对于顺序存储结构来说，效率是可以接受的，但 这样的表由于无序造成查找的效率很低。如果查找的数据集是有序线性表，并且是顺序存储的，查找可以用折半、插值、 斐波那契等查找算法来实现，可惜，因为有序，在插入和删除操作上，就需要耗费大量的时间。
* 二叉排序树（Binary Sort Tree）,又称为二叉査找树。它或者是一棵空树，或者 是具有下列性质的二叉树。
  * 若它的左子树不空，则左子树上所有结点的值均小于它的根结构的值;
  * 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值;
  * 它的左、右子树也分别为二叉排序树。
* 从二叉排序树的定义也可以知道，它前提是二叉树，然后它采用了递归的定义方 法，再者，它的结点间满足一定的次序关系，左子树结点一定比其双亲结点小，右子树结点一定比其双亲结点大。构造一棵二叉排序树的目的，其实并不是为了排序，而是**为了提高查找和插入删除关键字的速度**。不管怎么说，在一个有序数据集上的查找，速度总是要快于无序的数据集的，而二叉排序树这种非线性的结构，也有利于插入和删除的实现。

###### 二叉排序树查找操作

* 二叉树的结构

  ```
  /* 二叉村的二叉链表节点结构定义 */
  typedef struct BiTNode	/* 结点结构 */
  {
      int data;		/*结点数据*/
      struct BiTNode *lchild, *rchild; /* 左右孩子指针 */
  } BiTNode, *BiTree;
  ```

* 二叉排序树的查找算法

  ```
  /*递归查找二叉排序树T中是否存在key*/
  /*指针f指向T的双亲，其初始调用值为NULL */
  /*若查找成功，则指针p指向该数据元索结点，并返回TRUE */
  /*否则指针p指向查找路径上访问的最后一个结点并返回FALSE */
  Status SearchBST(BiTree T, int key, BiTree f, BiTree *p)
  {
  	if	(!T)	/*查找不成功*/
  	{
  		*p = f；
  		return FALSE;
  	} elseif ( key==T->data) /* 查找成功 */
  	{
          *p = T;
          return TRUE;
      } else if ( key < T->data )
      {
          return SearchBST(T->lchild, key, T, p) ;/*在左子树纏续查找 */
      } else {
          return SearchBST(T->rchild, key, T, p) ;/*在右子树继续查找 */
      }
  }
  ```

* 二叉排序树插入操作

  * 所谓的二叉排序树的插入，其实也就是将关键 字放到树中的合适位置而已

  ```
  /*当二叉排序树T中不存在关键字等于key的数据元素时，*/
  /*插入key并返回TRUE.否则返回FALSE */
  
  Status InsertBST (BiTree *T, int key)
  {
      BiTree p,s;
      if ( !SearchBST (*T, key, NULL, &p) ) /* 查找不成功 */ 
      {
          s = ( BiTree ) malloc ( sizeof ( BiTNode ));
          s->data = key;
          s->lchild = s->rchild = null; 
          
          /*插入s为新的根结点*/
          if (!p) {
          	*T = s;
          } else if ( key < p->data)
          {
          	p->lchild = s;
          } else
          {
          	p->rchild = s;
          }
          return TRUE;
      } 
  	return FALSE; /*树中已有关铤字相同的结点，不再插入*/
  }
  ```

* 二叉排序树删除操作

* 我们不能因为删除了结点，而让这棵树变得不满足二叉排序树的特性，所以删除需要考虑多种情况。

  * 删除二叉排序树中叶子结点
    * 删除它们对整棵树来说，其他结点的结构并未受到影响
  * 删除的结点只有左子树或只有右子树的情况
    * 将它的左子树或右子树整个移动到删除结点的位置即可，可以理解为独 子继承父业
  * 要删除的结点既有左子树又有右子树的情况
    * 将被删除节点的左子树的最大节点替换待删除节点（左子树最右节点）
    * 将被删除节点的左子树的最小节点替换待删除节点（右子树最左节点）
    * 中序遍历的前驱和后继节点元素

* 删除算法实现

  ```
  /*若二又排序树T中存在关铤字等于key的数据元素时，则除该数据元素站点，*/
  /*并返回TRUE;否则処回FALSE */
  Status DeleteBST ( BiTree *T, int key)
  {
      if (!*T) /*不存在关键字等于key的数据元* */
          return FALSE;
      else
      {
          if ( key= ( *T ) ->data ) /*找到关键字等于key的数据元*/
              return Delete (T);
          else if ( key < (*T)->data )
              return DeleteBST (&(*T ->lchild,key);
          else
              return DeleteBST (&(*T)->rchild,key );
      }
  }
  /*这段代码和前面的二叉排序树查找几乎完全相同，唯一的区别就在于找到元素时执行的是Delete方法，对当前结点进行删除操作。（可先找到元素，后执行移除）*/
                                
  /*从二又排序树中昌除结点p,并重接它的左或右子树。•/
  Status Delete (BiTree *p)
  {
      BiTree q,s;
      if ((*p) ->rchild = NULL )	/*右子树空則只需重接它的左子树•/
      {
      	q=*p； *p= (*p) ->lchild; free (q);
      }
      elseif ((*p) ->lchild-=NULL ) /* 只需重接它的右子树 */
      {
      	q=*p; *p = (*p ) ->rchild; free (q);
      }
      else	/*左右子树均不空*/
      {
          q=*p； 
          s= ( *p ) ->lchild;
          while (s->rchild)	/* 转左，然后向右到尽头，找持删结点的前驱*/
          {
              q=s; s->rchild; /*s指向被删站点的直接前驱*/
          }
          
          (*p)->data = s->data; 
          if (q != *p)
              q->rchild=s->lchild; /* 重接 q 的右子树•/
          else
              q->lchild=s->lchild; /* 重接 q 的左子树 */
          free (s);
      }
      return TRUE;
  }
  ```

---

###### 二叉排序树总结

* 总之，二叉排序树是以链接的方式存储，保持了链接存储结构在执行插入或删除 操作时不用移动元素的优点，只要找到合适的插入和删除位置后，仅需修改链接指针即可。插入删除的时间性能比较好。而对于二叉排序树的查找，走的就是从根结点到要查找的结点的路径，其比较次数等于给定值的结点在二叉排序树的层数。极端情况，最少为 1 次，即根结点就是要找的结点，最多也不会超过树的深度。也就是说， **二叉排序树的查找性能取决于二叉排序树的形状。可问题就在于，二叉排序树的形状是不确定的。** 例如. 数组元素的次序是从小到大有序，如｛35,37,47,51,58,62,73,88, 93,99｝,则二叉排序树就成了极端的右斜树，注意它依然是一棵二叉排序树。此时，查找结点99,需要10 次比较才可以得到结果。
* 我们希望二叉排序树是比较平衡的，即其深度与完全二叉树相同，均为 $\lfloor log_2n \rfloor + 1$,那么查找的时间复杂也就为 $O(logn)$ 近似于折半查找.
* 不平衡的最坏情况，查找时间复杂度为0（n），这等同于顺序查找。
* 如果我们希望对一个集合按二叉排序树査找，最好是把它构建成一棵平衡的二叉排序树。这样我们就引申出另一个问题，如何让二叉排序树平衡的问题。

---

##### 平衡二叉树（AVL树）

* 平衡二叉树(SMBalancing Binary Search Tree 或 Heigjit-Balanced Binary Search Tree),是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于 1。

* 它是一种高度平衡的二叉排序树。 那什么叫做高度平衡呢？意思是说，要么它是一棵空树，要么它的左子树和右子树都 是平衡二叉树，且左子树和右子树的深度之差的绝对值不超过 1. 

* 将二叉树上结点的左子树深度减去右子树深度的值称为**平衡因子 BF (Balance Factor)**,那么平衡二叉树上所有结点的平衡因子只可能是 -1、0和1。只要二叉树上有一个结点的平衡因子的绝对值大于1,则该二叉树就是不平衡的。

* 距离插入结点最近的，且平衡因子的绝对值大于 1 的结点为根的子树，我们称为 **最小不平衡子树**。

* **平衡二叉树实现原理**

* 平衡二叉树构建的基本思想就是在构建二叉排序树的过程中，每当插入一个结点 时，先检查是否因插入而破坏了树的平衡性，若是，则找出最小不平衡子树。在保持 二叉排序树特性的前提下，调整最小不平衡子树中各结点之间的链接关系，进行相应的旋转，使之成为新的平衡子树。

* 平衡二叉树，其实就是在二叉排序树创建过程中保证它的平衡性，一旦发现有不平衡的情况，马上处理，这样就不会造成不可收拾的情况出现。

* 当最小不平衡子树根 结点的平衡因子BF是大于 1 时，就右旋，小于 -1 时就左旋。插入结点后，最小不平衡子树的 BF 与它的子树的 BF 符号相反时，就需要对结点先进行一次旋转以使得符号相同后，再反向旋转一次才能够完成平衡操作。

* 节点插入后的不平衡情况

  * LL型
    * 由于在A的左孩子(L)的左子树(L)上插入新结点，使原来平衡二叉树变得不平衡，此时A的平衡因子由1增至2。显然，按照大小关系，结点B应作为新的根结点，其余两个节点分别作为左右孩子节点才能平衡，A结点就好像是绕结点B顺时针旋转一样。
  * RR型
    * 由于在A的右孩子(R)的右子树(R)上插入新结点，使原来平衡二叉树变得不平衡，此时A的平衡因子由-1变为-2。显然，按照大小关系，结点B应作为新的根结点，其余两个节点分别作为左右孩子节点才能平衡，A结点就好像是绕结点B逆时针旋转一样。
  * LR型
    * 由于在A的左孩子(L)的右子树(R)上插入新结点，使原来平衡二叉树变得不平衡，此时A的平衡因子由1变为2。显然，按照大小关系，结点C应作为新的根结点，其余两个节点分别作为左右孩子节点才能平衡。
  * RL型
    * 由于在A的右孩子(R)的左子树(L)上插入新结点，使原来平衡二叉树变得不平衡，此时A的平衡因子由-1变为-2。显然，按照大小关系，结点C应作为新的根结点，其余两个节点分别作为左右孩子节点才能平衡。

* 二叉排序树的结点结构

  ```c
  /*二叉树的二又链表结点结枸定义*/
  typedef struct BiTNode	/*结点结构*/
  {
      int data;	/*结点数据*/
      int bf;	 /*结点的平衡因子*/
      struct BiTNode *lchild,	*rchild;/*左右孩子指针*/
  } BiTNode, *BiTree;	
  ```

* 右旋操作算法

  ```c
  /*对以p为根的二叉排序树作右親处理，*/
  /*处理之后p指向新的树根结点，即旅捋处理之前的左子树的根结点*/
  void R_Rotate (BiTree *P )
  {
      BiTree L;
      L = (*P)->lchild;	/* L指向P的左子树根结点 */
      (*P)->lchild = L->rchild;	/* L的右子树挂接为P的左子树*/
      L->rchild= (*P);
      *P = L; /*P指向新的根结点*/
  }
  /*此函数代码的意思是说，当传入一个二叉排序树P,将它的左孩子结点定义为L, 将L的右子树变成P的左子树，再将P改成L的右子树，最后将L替换P成为根结 点。这样就完成了一次右旋操作*/
  ```

* 左旋操作算法 

  ```c
  /* 对以p为根的二叉排序树作左旋处理 */
  /* 处理之后P指向新的树根站点，即旋转处理之前的右子树的根结点 */
  void L_Rotate (BiTree *P)
  {
      BiTree R;
      R = (*P)->rchild;	/* R指向P的右子树根结点*/
      (*P)->rchild = R->lchild; /* R的左子树挂接为P的右子树*/ 
      R->lchild = ( *P);
      *P=R;	/* P指向新的根结点•/
  }
  /*这段代码与右旋代码是对称的*/
  ```

* 左平衡旋转处理的算法

  ```
  #define LH +1	/* 左高 */
  #define EH 0	/* 等高 */
  #define RH -1 /* 右高 */
  /*对以指针T所指結点为根的二叉树作左平街裁转处理*/
  /*本算法站束时，指卄T指向新的根结点•/
  1void LeftBalance (BiTree *T )
  2{
  3BiTree LrLr;
  4( *T)->lchild； /* L指向T的左子树根结点*/
  5switch ( L->bf )
  6{ /*检查T的左子树的平衡度，并作相应平街处理*/
  7case LH: /*新结点插入在T的左孩子的左子树上，要作单右旋处理*/
  8(*T ) ->bf=L->bf-EH;
  9R_Rotate(T);
  10break;
  11case RH: /* 新始点插入在T的左孩子的右子树上，妾作双叢处理*/
  12Lr=L->rchild;	/• Lr指向T的左孩子的右子树根*/
  13switch(Lr->bf ) /*修改T及其左孩子的平衡因子*/
  14(
  15case LH: ( *T) ->bf«RH;
  16L->bf=EH;
  #define LH +1	/* 左高 */
  #define EH 0	/* 等高 */
  #define RH -1 /* 右高 */
  /*对以指针T所指結点为根的二叉树作左平街裁转处理*/
  /*本算法站束时，指卄T指向新的根结点•/
  1void LeftBalance (BiTree *T )
  2{
  3BiTree LrLr;
  4( *T)->lchild； /* L指向T的左子树根结点*/
  5switch ( L->bf )
  6{ /*检查T的左子树的平衡度，并作相应平街处理*/
  7case LH: /*新结点插入在T的左孩子的左子树上，要作单右旋处理*/
  8(*T ) ->bf=L->bf-EH;
  9R_Rotate(T);
  10break;
  11case RH: /* 新始点插入在T的左孩子的右子树上，妾作双叢处理*/
  12Lr=L->rchild;	/• Lr指向T的左孩子的右子树根*/
  13switch(Lr->bf ) /*修改T及其左孩子的平衡因子*/
  14(
  15case LH: ( *T) ->bf«RH;
  16L->bf=EH;
  }
  }
  ```

  // todo

---

##### 多路查找树（B树）

* 若我们要操作的数据集非常大，大到内存已经没办法处理了怎么办呢？如数 据库中的上千万条记录的数据表、硬盘中的上万个文件等。在这种情况下，对数据的 处理需要不断从硬盘等存储设备中调入或调出内存页面。
* 一旦涉及到这样的外部存储设备，关于时间复杂度的计算就会发生变化，访问该集合元素的时间已经不仅仅是寻找该元素所需比较次数的函数，我们必须考虑对硬盘等外部存储设备的访问时间以及将会对该设备做出多少次单独访问。
* 试想一下，为了要在一个拥有几十万个文件的磁盘中查找一个文本文件，你设计 的算法需要读取磁盘上万次还是读取几十次，这是有本质差异的。此时，为了降低对 外存设备的访问次数，我们就需要新的数据结构来处理这样的问题。
* 一个结点只能存储一个元素，在元素非常多的时候，就使得要么树的度非常大 （结点拥有子树的个数的最大值），要么树的高度非常大，甚至两者都必须足够大才行。这就使得内存存取外存次数非常多，这显然成了时间效率上的瓶颈，这迫使我们 要打破每一个结点只存储一个元素的限制，为此引入了多路查找树的概念。
* 多路查找树（muiti-way search tree）, 其每一个结点的孩子数可以多于两个，且每一个结点处可以存储多个元素。由于它是查找树，所有元素之间存在某种特定的排序关系。

###### 2.3 树

* 2-3树是这样的一棵多路查找树：其中的每一个结点都具有两个孩子（我们称它 为 2 结点）或三个孩子（我们称它为 3 结点）。
* 一个2结点包含一个元素和两个孩子（或没有孩子），且与二叉排序树类似，左子 树包含的元素小于该元素，右子树包含的元素大于该元素。不过，与二叉排序树不同 的是，这个2结点要么没有孩子，要有就有两个，不能只有一个孩子。
* 一个3结点包含一小一大两个元素和三个孩子（或没有孩子），一个3结点要么没有孩子，要么具有3个孩子。如果某个3结点有孩子的话，左子树包含小于较小元素的元素，右子树包含大于较大元素的元素，中间子树包含介于两元素之间的元素。
  * 左子树
  * 右子树
  * 中子树
* 根据2-3树的定义，2-3树也可能会失去平衡，那么在插入和删除节点时也是需要动态维持平衡的，但维持平衡的策略和AVL树是不一样的。AVL树是通过旋转来恢复平衡的，而2-3树是通过节点分裂来维持的，因为2-3树中有一些2节点，这些2节点可以变成3节点来容纳插入节点，最后导致插入节点而不会让树失去平衡。如果2-3树中已经没有2节点可以分裂成3节点了呢？其实这种情况下已经可以直接插入节点了，这时候插入的位置不会导致有深度差超过1。

* 并且2-3树中所有的叶子都在同一层次上。
* 事实上，2-3树复杂的地方就在于新结点的插入和已有结点的删除。毕竟，每个结点可能是 2 结点也可能是 3 结点，要保证所有叶子都在同一层次，是需要进行一番 复杂操作的

* **树的插入分析**

* 对于2-3树的插入来说，与二叉排序树相同，插入操作一定是发生在叶子结点 上。可与二叉排序树不同的是，2-3树插入一个元素的过程有可能会对该树的其余结构产生连锁反应。

  * 对于空树，插入一个2结点即可，这很容易理解。
  * 插入结点到一个 2 结点的叶子上。应该说，由于其本身就只有一个元素，所以只需要将其升级为 3 结点即可。当然，要视插入的元素与当前叶子结点的元素比较大 小后，决定谁在左谁在右。
  * 要往 3 结点中插入一个新元素。因为3结点本身已经是2-3树的结点最大容量（已经有两个元素），因此就需要将其拆分，且将树中两元素或插入元素的三者中选择其一向上移动一层。复杂的情况也正在于此。
    * 插入节点的父节点为二节点
      * 拆分当前插入节点(三节点)，并将父节点升级为三节点
        * 二节点 -> 三节点：(节点多出一个元素， 多处一个字节点； 2个)；
    * 插入节点的某祖先节点为二节点
      * 将第一个三节点的祖先升级为三节点
    * 插入节点的祖先节点均为三节点
      * 将当前节点到跟节点的三节点依次拆分为二节点（会导致树的高度增加）

* **树的删除分析**
  * 所删除元素位于一个3结点的叶子结点上，这非常简单，只需要在该结点处删除该元素即可，不会影响到整棵树的其他结点结构。
  * 所删除的元素位于一个2结点上，即要删除的是一个只有一个元素的结点。如 果按照以前树的理解，删除即可，可现在的2・3树的定义告诉我们这样做是不可以的。删除元素节点导致它的夫节点少了一个节点（2->1, 3->2 节点， 不满足定义）
    * 此结点的双亲也是2结点，且拥有一个3结点的右孩子。
      * 左旋操作
    * 此结点的双亲是2结点，它的右孩子也是2结点。
      * 如果直接左旋会造成没有右孩子，因此需要对整棵树变形
      * 将右孩子补充为三节点后进行左旋操作
    * 此结点的双亲是一个3结点。
      * 将此结点拆分
    * 如果当前树是一个满二叉树的情况，此时删除任何一个叶子都会使得整 棵树不能满足2・3 树的定义。
    * 所删除的元素位于非叶子的分支结点。
      * 我们通常是将树按中序遍历后得到此元素的前驱或后继元素，考虑让它们来补位即可。

* 2-3树的构建过程

  ```
  
  ```

  

###### 2-3-4 树

* 有了 2-3树的讲解，2-J4树就很好理解了，它其实就是2.3树的概念扩展，包括 了 4结点的使用。一个4结点包含小中大三个元素和四个孩子（或没有孩子）,一个4结点要么没有孩子，要么具有4个孩子。如果某个4结点有孩子的话，左子树包含小 于最小元素的元素；第二子树包含大于最小元素，小于第二元素的元素；第三子树包 含大于第二元素，小于最大元素的元素；右子树包含大于最大元素的元素。
*   2-3-4树跟2-3树差不多，只不过是把节点的最大子节点个数扩充到了4个，所以2-3-4树的节点有2节点3节点4节点四种，当发现插入节点是2节点或3节点时，就可以把节点进行扩容直接插入，如果发现是4节点的话，就向上回溯，把4节点进行分裂，并把中间的元素向上提。向上提时不可能回溯超过两层，因为4节点的子节点不可能再有子节点了。在插入的时候，如果发现插入的节点已经是4节点了，那么就要向上回溯分裂，如果发现插入节点的父节点是2或3节点，就直接上提，然后当前节点分裂，如果发现父节点是4节点，则父节点也分裂，这样就导致上提不会提到父节点的父节点，所以父节点的父节点不会增加元素，因此一个4节点的子节点不会再有子节点了。所以插入位置的如果是4节点，要向上提回溯也不可以回溯很多层，这样在插入或者删除操作时效率就比普通的二叉平衡树高多了。一但发现插入位置已经是4节点，而把插入节点分裂上提导致父节点也成为4节点，就将父节点也分裂。这样能保证如果父节点已经是4节点，再向上提可父节点无法再分裂的情况。用这处条件再来约束就可以保证所有的4节点都在最下面一层，而且各个子树的高度一样，这样树一定是完全平衡的。

###### B树

* B树中所有节点中孩子节点个数的最大值，通常我们用m表示（m >= 3），成为m阶B树。
  * 2-3树其实就是最简单的B树，每个非叶子节点都有2-3个孩子节点，所以2-3和3阶B树是同一个东西。

* B树(B・tree)是一种平衡的多路査找树，2-3树和2-3-4树都是B树的特例。结点最大的孩子数目称为B树的阶(order),因此，2-3树是3阶B树，2-3-4树是4 阶B树。
* m阶的B树具有如下属性
  * 每个节点**最多有m个分支**（子树），除根节点和叶子节点之外的节点最少都应该含有**ceil(m/2)** 个分支（**ceil**表示向上取整），所以非根非叶子的分支的数量范围为 **[ ceil(m/2),m]**。根节点最少可以有两个分支。
  * 如果根结点不是叶结点，则其至少有两棵子树。
  * 某个节点中含有m个分支，那么它所包含的**关键词**就是**（m-1）**个，所以在m阶B树中，他的关键词的数量范围就是**[ceil(m/2)-1,m-1] ,**并且在节点中关键词的都是按照递增顺序排列的。
  * 除叶子节点外所有的节点中的**关键词都是互不相等**的。
  * B树中的叶子节点都是处在同一层中，一般都是用空指针表示，表示查找失败。
  * **B树中某个节点中左子树所有的关键词都是小于这个节点的，右子树中所有的关键词都是大于这个节点的**。这里就是和二叉排序树是相同的
* **B树的查找**
  * 在B树上查找的过程是一个顺指针查找结点和在结点中查找关键字的交叉过程。
  *  B树的查找查找成功就是在除叶子节点之外的点中找到了值相等的关键词，失败就是指一直到叶子节点都没有找到相等的关键词。
  *   我们假设需要查找的关键词是key，查找的过程 如下：
    1. key先和根节点中的关键词比较，如果在在节点中找到key == k[i](表示节点中第i个关键词),那么就表示查找成功。
    2. 如果上面的节点没有找到匹配的值，我们就需要在再节点的关键词中寻找 k[i] < key  <k[i+1] ,或者 key < k[0],或者 key > k[n],然后根据指针所指示的子树继续查找。
    3. 如果最后遇到空指针，则证明查找不成功。
* **B树的插入**
  *   在B树插入的过程中我们主要需要注意的就是各个节点中关键词的个数，我们上面说过关键词的个数范围应该在 ([ceil[m/2]-1,m-1])之间。在插入过程中首先应该在B树中找到我们需要插入的位置，如果这个待插入的元素以前是不存在于B树中的，我们就一直会找到叶子节点上，那么我们需要的位置就是这个叶子节点之上的子节点中相应位置。我们这里称底层非叶子节点为底层节点，所以我们一般找到的位置都是在**底层节点**上，我们先将待插入的节点插入到这个底层节点中，然后我们需要考虑关键词超限的情况。也就是说如果你太富裕了，需要和那些比较穷的节点中和一下，保持一个平衡的状态。
    * 拆入元素时，对插入的节点进行升级。若当前节点元素已满， 则将当前节点进行拆分并对父节点进行升级
    * 在插入时，我们还有时会遇到另外一种情况：父亲节点已经到达上限，但是它的子节点中又含有一个过度富裕的。这时将我们的过度富裕的节点中的中间关键词拿到父亲节点，这是我们的根节点就是过度富裕的了，这时根节点就没有父亲节点了，那么我们只好通过增加树的高度来完成了。
* **B树的删除**
  * 删除中我们首先需要找到待删除的关键词，当然在删除过程中我们有事也会破坏B树的特性，这时我们就需要进行一定的操作来来使这棵树重新成为B树。
  * 首先我们需要知道元素的相近元素：如果某一个元素存在左右孩子节点的话，那么他的左孩子中的最大值和右孩子的最小值就是这个元素的相近节点。（直接前驱元素与直接后继元素）
    * 我们要在B-树找到需要删除的元素的位置，将该节点进行删除，如果该元素存在相近元素，我们就把相近元素上移到父节点
    * 如果某节点中元素个数小于最小的元素数目，首先我们先看看相邻的兄弟节点是否过得还富裕，如果过的还富裕的话，那么直接平均一下节点的关键词数目就好。
    * 如果相邻的兄弟节点都是过的十分紧迫，那么我们就和邻近的兄弟节点以及一个父亲节点进行合并操作，然后再进行后面的移动。
* B树的插入和删除，方式是与2-3树和2-3-4树相类似的，只不过阶数可能会很大而已。
* 如果内存与外存交换数据次数频繁，会造成了时间效率 上的瓶颈，那么B树结构怎么就可以做到减少次数呢？
  * 我们的外存，比如硬盘，是将所有的信息分割成相等大小的页面，每次硬盘读写的都是一个或多个完整的页面，对于一个硬盘来说，一页的长度可能是211到214个 字节。
  * 在一个典型的B树应用中，要处理的硬盘数据量很大，因此无法一次全部装入内 存。因此我们会对B树进行调整，使得B树的阶数（或结点的元素）与硬盘存储的页 面大小相匹配。比如说一棵B树的阶为1001 （即1个结点包含1000个关键字），高 度为2,它可以储存超过10亿个关键字，我们只要让根结点持久地保留在内存中，那 么在这棵树上，寻找某一个关键字至多需要两次硬盘的读取即可。这就好比我们普通 人数钱都是一张一张的数，而银行职员数钱则是五张、十张，甚至几十张一数，速度 当然是比常人快了不少。
  * 通过这种方式，在有限内存的情况下，每一次磁盘的访问我们都可以获得最大数 量的数据。由于B树每结点可以具有比二叉树多得多的元素，所以与二叉树的操作不同，它们减少了必须访问结点和数据块的数量，从而提高了性能。可以说，B树的数 据结构就是为内外存的数据交互准备的。

* 分析： 对于n个关键字的m阶B树，最坏情况是要查找几次呢？

  ```
  
  ```

* B 树正确性分析

  ```
  
  ```

---

###### B+树

* 尽管前面我们已经讲了 B树的诸多好处，但其实它还是有缺陷的。对于树结构来说，我们都可以通过中序遍历来顺序查找树中的元素，这一切都是在内存中进行。可是在B树结构中，我们往返于每个结点之间也就意味着，我们必须得在硬盘的 页面之间进行多次访问，如图8-8-18所示，我们希望遍历这棵B树，假设每个结点 都属于硬盘的不同页面，我们为了中序遍历所有的元素，页面2一页面1-页面3-页 面1—页面4一■页面1-•页面5o而且我们每次经过结点遍历时，都会对结点中的元素 进行一次遍历，这就非常糟糕。有没有可能让遍历时每个元素只访问一次呢？

* 了能够解决所有元素遍历等基本问题，我们在原有的B树结构基础 上，加上了新的元素组织方式，这就是B+树。B+树是应文件系统所需而出的一种B树的变形树，注意严格意义上讲，它其实已经不是定义的树了。在B树中，每一个元素在该树中只出现一次，有可能在叶子结点上，也有可能在分支结点上。而在B+树中，岀现在分支结点中的元素会被当作它们在该分支结点位置的中序后继者（叶子结点）中再次列出。另外，每一个叶子结点都会保存一个指向后一叶子结点的指针。

* 一棵m阶的B+树和m阶的B树的差异在于：

  * 有n棵子树的结点中包含有n个关键字；
  *  所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
    * 每个叶节点都带有指向下一个节点的指针，也就形成了一个有序链表。
    * 叶子结点才带有实际的数据记录信息（比如只想数据库的一行记录）。而中间节点仅仅是保存索引信息，没有任何数据关联。
  * 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。
    * 跟节点的最大元素也就等同于 B+ 树的最大元素。以后无论插入或者删除多少个元素，始终需要保持最大元素在跟节点中。

* **B+树的优势：**

  1. 单一节点存储更多的元素，使得查询的IO次数更少。

  2. 所有查询都要查找到叶子节点，查询性能稳定。

  3. 所有叶子节点形成有序链表，便于范围查询。

  * B+树中间节点不保存数据信息， 所以同样大小的磁盘页可以保存更多的节点信息。意味着在数据量相同的情况下，B+树相较而言更加‘矮胖’，因此 IO 查询次数也更少。
  * B-树的查询可能在内部节点终止，性能不稳定。而B+树的每一次查找都是稳定的。
  * B-树的范围查找比较麻烦。在中序查找时需要在不同磁盘叶中切换。而 B+树的叶节点保存下一节点的链接，可直接访问。

  

* B+树的数据结构最大的好处就在于，如果是要随机查找，我们就从根结点出发， 与B树的查找方式相同，只不过即使在分支结点找到了待查找的关键字，它也只是用 来索引的，不能提供实际记录的访问，还是需要到达包含此关键字的终端结点。

* 如果我们是需要从最小关键字进行从小到大的顺序查找，我们就可以从最左侧的 叶子结点出发，不经过分支结点，而是延着指向下一叶子的指针就可遍历所有的关 键字。

* B+树的结构特别适合带有范围的查找。比如查找我们学校18〜22岁的学生人 数，我们可以通过从根结点出发找到第一个18岁的学生，然后再在叶子结点按顺序 查找到符合范围的所有记录。

* B+树的插入、删除过程也都与B树类似，只不过插入和删除的元素都是在叶子结 点上进行而已。

---

###### 散列表查找（哈希表）

* 前面的顺序表查找时，我们曾经说过，如果你要查找某个关键字的记录， 就是从表头开始，挨个的比较记录a[i]与key的值是还是“主”，直到有相等才 算是查找成功，返回私到了有序表查找时，我们可以利用a[i]与key的大小来折半査找，直到相等时査找成功返回。 最终我们的目的都是为了找到那个i,其实 也就是相对的下标，再通过顺序存储的存储位置计算方法，LOC (ai) =LOC (a0) +  (i-1) xc ,也就是通过第一个元素内存存储位置加上 i-1 个单元位置，得到最后的内存地址。此时我们发现，为了查找到结果，之前的方法“比较”都是不可避免的，但这是否真的有必要？能否直接通过关键字key得到要查找的记录内存存储位置呢？
* **散列表查找定义**

* 要通过某个函数f,使得， 存储位置=f(关键字)； 那样我们可以通过査找关键字不需要比较就可获得需要的记录的存储位置。这就是一种新的存储技术 - 散列技术。
* 散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系f,使得 每个关键字key对应一个存储位置f (key) 。 查找时，根据这个确定的对应关系找到给定值key的映射f (key), 若查找集合中存在这个记录，则必定在f (key)的位置上。
* 这里我们把这种对应关系 f 称为散列函数，又称为哈希 hash 函数。按这个思 想，采用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间称为散列表或哈希表Hashtable。那么关键字对应的记录存储位置我们称为散列地址。
* **散列表查找步骤**
  * 在存储时，通过散列函数计算记录的散列地址，并按此散列地址存储该记 录。总之，不管什么记录，我们都需要用同一个散列函数计算出地址再存储。
  * 当查找记录时，我们通过同样的散列函数计算记录的散列地址，按此散列地址访问该记录。说起来很简单，在哪存的，上哪去找，由于存取用的是同一个散列函 数，因此结果当然也是相同的。
* 散列技术既是一种存储方法，也是一种查找方法。然而它与线性表、 树、图等结构不同的是，前面几种结构，数据元素之间都存在某种逻辑关系，可以用 连线图示表示出来，而散列技术的记录之间不存在什么逻辑关系，它只与关键字有关联。因此，散列主要是面向查找的存储结构。
* 散列技术最适合的求解问题是査找与给定值相等的记录。对于查找来说，**简化了比较过程**，效率就会大大提高。但万事有利就有弊，散列技术不具备很多常规数据结 构的能力。
  * 比如那种同样的关键字，它能对应很多记录的情况，却不适合用散列技术。
  * 散列表也不适合范围查找，比如査找一个班级18〜22岁的同学，在散列表 中没法进行。想获得表中记录的排序也不可能
  * 最大值、最小值等结果也都无法从 散列表中计算出来。
* 在理想的情况下，每一个关键字，通过散列函数计算出来的 地址都是不一样的，可现实中，这只是一个理想。我们时常会碰到两个关键字key1, key2,但是却有f (key1)=f (key2),这种现象我们称为冲突(collisicm),并把key1和 key2 称为这个散列函数的同义词(synonym).出现了冲突当然非常糟糕，那将造成数据查找错误。
* 散列函数应该如何设计
  * 设计 一个简单、均匀、存储利用率高的散列函数是散列技术中最关键的问题。
  * 如何处理冲突

###### 散列函数的构造方法

* **计算简单**  因此散列函数的计算时间不应该超过其他査找技术与关键字比较的时间。

* **散列地址分布均匀**   尽量让散列地址均匀地分布在 存储空间中，这样可以保证存储空间的有效利用，并减少为处理冲突而耗费的时间。

  

* **直接定址法**

* 取关键字的某个线性函数值为散列地址，即 f ( key ) =a * key + b ( a、b 为常数)

* 这样的散列函数优点就是简单、均匀，也不会产生冲突，但问题是这需要事先知道关键字的分布情况，适合查找表较小且连续的情况。由于这样的限制，在现实应用中，此方法虽然简单，但却并不常用

  

* **数字分析法**

* 抽取方法是使用关键字的一部分来计算散列存储位置的方法，这在散列函数中是常常用到的手段。

* 数字分析法通常适合处理关键字位数比较大的情况，如果事先知道关键字的分布 且关键字的若干位分布较均匀，就可以考虑用这个方法。

  

* **平方取中法**

* 这个方法计算很简单，假设关键字是1234,那么它的平方就是1522756,再抽取 中间的3位就是227,用做散列地址。再比如关键字是4321,那么它的平方就是 18671041,抽取中间的3位就可以是671,也可以是710,用做散列地址。平方取中 法比较适合于不知道关键字的分布，而位数又不是很大的情况。

  

* **折叠法**

* 折叠法是将关键字从左到右分割成位数相等的几部分(注意最后一部分位数不够 时可以短些)，然后将这几部分叠加求和，并按散列表表长，取后几位作为散列地址。

* 比如我们的关键字是9876543210,散列表表长为三位，我们将它分为四组， 987|654|321|0,然后将它们叠加求和987+654+321+0=1962,再求后3位得到散列 地址为962.有时可能这还不能够保证分布均匀，不妨从一端向另一端来回折叠后对齐相加。 比如我们将987和321反转，再与654和0相加，变成789+654+123+0=1566,此 时散列地址为566O折叠法事先不需要知道关键字的分布，适合关键字位数较多的情况。



* **除留余数法**

* 此方法为最常用的构造散列函数方法。对于散列表长为m的散列函数公式为： f ( key ) = key mod p (p <= m)

  mod是取模(求余数)的意思。事实上，这方法不仅可以对关键字直接取模，也可在折叠、平方取中后再取模。很显然，本方法的关键就在于选择合适的P, P如果选得不好，就可能会容易产生同义词。

* 若散列表表长为m,通常p为小于或等于表长(最好接 近m)的最小质数或不包含小于20质因子的合数。



* **随机数法**
* 选择一个随机数，取关键字的随机函数值为它的散列地址。



* 现实中，应该视不同的情况采用不同的散列函数。我们只能给出一些考虑 的因素来提供参考：
  * 计算散列地址所需的时间。
  * 关键字的长度。
  * 散列表的大小。
  * 关键字的分布情况。
  * 记录查找的频率。

###### 处理散列冲突的方法

* 设计得再好的散列函数也不可能完全避免冲突。

* **开放定址法**

  * 所谓的开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。（di 为散列地址的求址次数）
    $$
    f_i(key) = (f(key) + d_i) MOD m (d_i=1,2,3.....,m-1)
    $$

  * 这种解决冲突的开放定址法称为线性探测法。
  * 我们在解决冲突的时候，还会碰到本来都不是同义词却需要争夺一个地址的情况，我们称这种现象为**堆积**。很显然，堆积的出现，使得我们需要不断处理冲突，无论是存入还是查找效率都会大大降低。

* 







